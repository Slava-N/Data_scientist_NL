{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = pd.read_csv('./homework/train.csv')\n",
    "test = pd.read_csv('./homework/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание:\n",
    "1. Подготовка данных\n",
    "2. Импорт библиотек моделей\n",
    "3. Подбор параметров для Random Forest\n",
    "4. Подбор параметров для Gradient Boosting\n",
    "5. Подбор параметров для Decision Tree\n",
    "6. Подбор параметров для SVM\n",
    "7. Подбор параметров для Logistic Regression\n",
    "8. Формирование матрицы предсказаний нескольких моделей\n",
    "9. Объединение предсказаний by Logistic Regression\n",
    "10. Формирование файла для отправки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "\n",
    "\n",
    ".\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем пропуски в данных медианными \n",
    "# значениями факторов на обучающей выборке\n",
    "train_median = train.median()\n",
    "train_imp = train.fillna(train_median)\n",
    "test_imp = test.fillna(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Бинаризуем категориальные признаки\n",
    "CATEGORY_COL = ['Sex', 'Pclass', 'Embarked']\n",
    "train_dummies = pd.get_dummies(train_imp, columns=CATEGORY_COL, drop_first=True)\n",
    "test_dummies = pd.get_dummies(test_imp, columns=CATEGORY_COL, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_male  Pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN         1         0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85         0         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN         0         0   \n",
       "3  35.0      1      0            113803  53.1000  C123         0         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN         1         0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  \n",
       "0         1           0           1  \n",
       "1         0           0           0  \n",
       "2         1           0           1  \n",
       "3         0           0           1  \n",
       "4         1           0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаляем лишние столбцы\n",
    "DROP_COL = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "TARGET_COL = 'Survived'\n",
    "X_train = train_dummies.drop(DROP_COL + [TARGET_COL], axis=1)\n",
    "y_train = train_dummies[TARGET_COL]\n",
    "X_test = test_dummies.drop(DROP_COL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Sex_male  Pclass_2  Pclass_3  Embarked_Q  \\\n",
       "0  22.0      1      0   7.2500         1         0         1           0   \n",
       "1  38.0      1      0  71.2833         0         0         0           0   \n",
       "2  26.0      0      0   7.9250         0         0         1           0   \n",
       "3  35.0      1      0  53.1000         0         0         0           0   \n",
       "4  35.0      0      0   8.0500         1         0         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стеккинга\n",
    "\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def cross_val_predict_proba(estimator, X_train, y_train):\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "    return cross_val_predict(estimator, X_train, y_train, cv=kfold, method='predict_proba')\n",
    "\n",
    "# TODO: подобрать гиперпараметры для ансамблей\n",
    "\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №1 для Random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_estimators':[10,50,100],\n",
    "       'max_features':[3,5,9],\n",
    "       'max_depth':[2,6,10],\n",
    "       'min_samples_leaf':[10,30,70,100],\n",
    "        'warm_start':[0,1]\n",
    "       }\n",
    "\n",
    "gridSearchRandomForest = GridSearchCV(RandomForestClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_RFC = gridSearchRandomForest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 5,\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 10,\n",
       " 'warm_start': 0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_RFC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.02538443,  0.02255803,  0.10336322,  0.11996859,  0.19009942,\n",
       "         0.1966064 ,  0.02187318,  0.02130675,  0.09817624,  0.09581733,\n",
       "         0.19059676,  0.20353001,  0.02340204,  0.02188891,  0.10875982,\n",
       "         0.1058777 ,  0.19878376,  0.18084979,  0.02045095,  0.020037  ,\n",
       "         0.09518588,  0.09212554,  0.18863297,  0.1902402 ,  0.02059829,\n",
       "         0.02069151,  0.09583628,  0.09514672,  0.19845915,  0.19166392,\n",
       "         0.02222651,  0.01982647,  0.09795988,  0.09675747,  0.19960999,\n",
       "         0.19428557,  0.02209318,  0.01953906,  0.09551013,  0.09867877,\n",
       "         0.19277138,  0.19433242,  0.02175629,  0.02149296,  0.09848136,\n",
       "         0.099819  ,  0.1949721 ,  0.20116967,  0.02392721,  0.0223105 ,\n",
       "         0.10417557,  0.1038602 ,  0.19911522,  0.20780081,  0.02231812,\n",
       "         0.02098185,  0.10613573,  0.10508555,  0.20053542,  0.20100701,\n",
       "         0.02185535,  0.02319729,  0.105259  ,  0.09992474,  0.19813907,\n",
       "         0.20224369,  0.02109504,  0.02282524,  0.09849435,  0.09897518,\n",
       "         0.19673675,  0.19684047,  0.02198821,  0.02357596,  0.10044521,\n",
       "         0.10118532,  0.20570952,  0.19943249,  0.02252722,  0.02137983,\n",
       "         0.10575294,  0.11099225,  0.20228887,  0.20479602,  0.02214044,\n",
       "         0.02316374,  0.10966158,  0.11053306,  0.19772375,  0.22146648,\n",
       "         0.02637243,  0.02169102,  0.09808075,  0.10535955,  0.19024587,\n",
       "         0.18853962,  0.02208501,  0.02322698,  0.10714447,  0.10509866,\n",
       "         0.20959646,  0.21036899,  0.02191174,  0.02145451,  0.10314751,\n",
       "         0.11219329,  0.2086392 ,  0.19710124,  0.02012718,  0.02135956,\n",
       "         0.09949064,  0.0970397 ,  0.20060444,  0.19488299,  0.02097565,\n",
       "         0.02137202,  0.0977515 ,  0.09690678,  0.19675279,  0.19132555,\n",
       "         0.02477032,  0.02601254,  0.11778754,  0.11652452,  0.2327953 ,\n",
       "         0.23434126,  0.02281284,  0.02342969,  0.11604226,  0.12365091,\n",
       "         0.22079426,  0.22210169,  0.02233571,  0.02092749,  0.10302633,\n",
       "         0.10680926,  0.21583033,  0.20617187,  0.02146822,  0.02290177,\n",
       "         0.10493243,  0.10331923,  0.20218009,  0.1954838 ,  0.02289253,\n",
       "         0.0230177 ,  0.10235983,  0.10206139,  0.20479894,  0.20524174,\n",
       "         0.02263725,  0.02091038,  0.10089928,  0.10205621,  0.19934851,\n",
       "         0.20140135,  0.02279615,  0.02069378,  0.09659201,  0.09860021,\n",
       "         0.19648331,  0.19652325,  0.02094531,  0.02022988,  0.09965706,\n",
       "         0.10180837,  0.19319159,  0.19300956,  0.02290922,  0.02486455,\n",
       "         0.11029565,  0.10840732,  0.2169866 ,  0.21665293,  0.02366704,\n",
       "         0.02236843,  0.09847307,  0.10277581,  0.19970155,  0.1999777 ,\n",
       "         0.02103996,  0.02137822,  0.09982741,  0.10055369,  0.1946947 ,\n",
       "         0.19182646,  0.0205214 ,  0.02149916,  0.0970704 ,  0.09657776,\n",
       "         0.19012421,  0.18975973,  0.02696639,  0.02587122,  0.1229955 ,\n",
       "         0.12120318,  0.23765075,  0.23101044,  0.0234583 ,  0.02350253,\n",
       "         0.10824573,  0.1102863 ,  0.21873426,  0.22362548,  0.02456874,\n",
       "         0.02382308,  0.11174005,  0.1051172 ,  0.20305616,  0.20456243,\n",
       "         0.02049202,  0.0235641 ,  0.10512483,  0.09772295,  0.19714117,\n",
       "         0.20117855]),\n",
       " 'mean_score_time': array([ 0.00274044,  0.00201136,  0.00870579,  0.01118279,  0.01463509,\n",
       "         0.01365107,  0.00237638,  0.00214845,  0.00880235,  0.00753146,\n",
       "         0.01522702,  0.01536912,  0.00233769,  0.00251788,  0.00844997,\n",
       "         0.00848848,  0.01414371,  0.01484329,  0.00208831,  0.00197893,\n",
       "         0.00740927,  0.00752276,  0.0137676 ,  0.01546204,  0.00196576,\n",
       "         0.00257146,  0.00696677,  0.00736105,  0.01449394,  0.01462018,\n",
       "         0.00207865,  0.00202149,  0.00810248,  0.00736606,  0.01586276,\n",
       "         0.01457423,  0.00209004,  0.00200468,  0.00803995,  0.00737542,\n",
       "         0.01642823,  0.01376611,  0.00288546,  0.00234586,  0.00884509,\n",
       "         0.00801903,  0.01528269,  0.01472121,  0.00201994,  0.0019837 ,\n",
       "         0.0074724 ,  0.00698155,  0.0137316 ,  0.01603621,  0.00231528,\n",
       "         0.00199473,  0.00697935,  0.00818068,  0.01403242,  0.01317072,\n",
       "         0.00233573,  0.00264394,  0.00941169,  0.00805831,  0.01384705,\n",
       "         0.01318485,  0.00194103,  0.0031628 ,  0.00728279,  0.00700873,\n",
       "         0.0149706 ,  0.01316476,  0.00214195,  0.00225151,  0.00835663,\n",
       "         0.00819463,  0.01640046,  0.01460946,  0.00235051,  0.00204396,\n",
       "         0.007967  ,  0.00745285,  0.01453424,  0.01641077,  0.00260329,\n",
       "         0.00238305,  0.00771171,  0.00910664,  0.01513636,  0.01866674,\n",
       "         0.00283575,  0.00264561,  0.00785953,  0.00840038,  0.01361424,\n",
       "         0.01349235,  0.0023948 ,  0.00210655,  0.0081495 ,  0.00751984,\n",
       "         0.01566875,  0.01427901,  0.0020498 ,  0.00244647,  0.00791019,\n",
       "         0.00817382,  0.01513821,  0.01505047,  0.00202125,  0.00201976,\n",
       "         0.00748652,  0.00706673,  0.01629877,  0.0171895 ,  0.00195563,\n",
       "         0.00198096,  0.00775945,  0.00809866,  0.01346415,  0.01509798,\n",
       "         0.00206941,  0.00215071,  0.00808716,  0.00765872,  0.01478535,\n",
       "         0.01464999,  0.00215858,  0.00255978,  0.00797814,  0.00903946,\n",
       "         0.01531321,  0.01553106,  0.00207257,  0.00205308,  0.00897646,\n",
       "         0.00780803,  0.01392388,  0.01557058,  0.00224674,  0.00202596,\n",
       "         0.00840884,  0.00866741,  0.01446074,  0.01321203,  0.00220823,\n",
       "         0.00257409,  0.00764245,  0.00880986,  0.01634383,  0.01499802,\n",
       "         0.00209272,  0.00331235,  0.00780278,  0.00731742,  0.01554525,\n",
       "         0.01420742,  0.0020923 ,  0.00200999,  0.00737494,  0.00730872,\n",
       "         0.01541364,  0.01578701,  0.00210637,  0.00202197,  0.00778025,\n",
       "         0.00751716,  0.01522076,  0.0168978 ,  0.00209224,  0.00269222,\n",
       "         0.00746506,  0.00947618,  0.0183475 ,  0.01509881,  0.0022192 ,\n",
       "         0.00206304,  0.00725895,  0.00895274,  0.01583225,  0.01509404,\n",
       "         0.00226974,  0.00218743,  0.00869131,  0.00724375,  0.01428401,\n",
       "         0.01599663,  0.00204319,  0.00197977,  0.00702667,  0.00737798,\n",
       "         0.01469791,  0.01400501,  0.00211376,  0.002406  ,  0.00908351,\n",
       "         0.0086332 ,  0.01676732,  0.01665908,  0.00243247,  0.00212425,\n",
       "         0.0072214 ,  0.00732422,  0.016348  ,  0.01609707,  0.00205827,\n",
       "         0.00205445,  0.00733292,  0.00791723,  0.01567537,  0.01491326,\n",
       "         0.00236696,  0.00207746,  0.00755805,  0.00882196,  0.01451677,\n",
       "         0.01333439]),\n",
       " 'mean_test_score': array([ 0.79124579,  0.77665544,  0.79685746,  0.78900112,  0.78563412,\n",
       "         0.80246914,  0.77216611,  0.78002245,  0.77553311,  0.77216611,\n",
       "         0.79236813,  0.77328844,  0.76430976,  0.77777778,  0.7687991 ,\n",
       "         0.77665544,  0.77328844,  0.77665544,  0.76767677,  0.76655443,\n",
       "         0.76655443,  0.77890011,  0.76655443,  0.77553311,  0.78563412,\n",
       "         0.78451178,  0.78900112,  0.79124579,  0.78226712,  0.79349046,\n",
       "         0.79124579,  0.77890011,  0.78114478,  0.78002245,  0.77777778,\n",
       "         0.78900112,  0.78114478,  0.77890011,  0.78114478,  0.76767677,\n",
       "         0.78675645,  0.78787879,  0.78451178,  0.78226712,  0.77777778,\n",
       "         0.78338945,  0.78675645,  0.77665544,  0.78002245,  0.78338945,\n",
       "         0.77890011,  0.77665544,  0.77777778,  0.77665544,  0.77890011,\n",
       "         0.77890011,  0.77890011,  0.77890011,  0.77890011,  0.77890011,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.80808081,  0.81144781,  0.81369248,\n",
       "         0.80920314,  0.81144781,  0.81369248,  0.78787879,  0.79124579,\n",
       "         0.7979798 ,  0.79349046,  0.79236813,  0.78338945,  0.76655443,\n",
       "         0.76655443,  0.77777778,  0.77553311,  0.7687991 ,  0.7654321 ,\n",
       "         0.78451178,  0.78675645,  0.76992144,  0.76767677,  0.77553311,\n",
       "         0.77104377,  0.82267116,  0.81144781,  0.81481481,  0.81930415,\n",
       "         0.81481481,  0.81481481,  0.78900112,  0.79012346,  0.79349046,\n",
       "         0.78787879,  0.79236813,  0.79461279,  0.77777778,  0.77777778,\n",
       "         0.77328844,  0.7687991 ,  0.78787879,  0.77553311,  0.78675645,\n",
       "         0.77216611,  0.78002245,  0.78675645,  0.78900112,  0.78563412,\n",
       "         0.80808081,  0.81144781,  0.8047138 ,  0.80808081,  0.81481481,\n",
       "         0.81032548,  0.79124579,  0.79910213,  0.7979798 ,  0.79685746,\n",
       "         0.79685746,  0.7979798 ,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.80695847,\n",
       "         0.81144781,  0.81144781,  0.81144781,  0.81144781,  0.81593715,\n",
       "         0.78563412,  0.78900112,  0.79349046,  0.80359147,  0.79349046,\n",
       "         0.79910213,  0.79012346,  0.78226712,  0.76992144,  0.78451178,\n",
       "         0.78114478,  0.76992144,  0.76430976,  0.77441077,  0.77104377,\n",
       "         0.76318743,  0.77104377,  0.76430976,  0.82154882,  0.80808081,\n",
       "         0.81144781,  0.81257015,  0.80695847,  0.81144781,  0.79124579,\n",
       "         0.79236813,  0.79685746,  0.79349046,  0.79349046,  0.79236813,\n",
       "         0.78451178,  0.76992144,  0.78338945,  0.78226712,  0.78114478,\n",
       "         0.78900112,  0.77328844,  0.79012346,  0.78563412,  0.78451178,\n",
       "         0.78114478,  0.78114478,  0.80920314,  0.80808081,  0.81257015,\n",
       "         0.81032548,  0.81257015,  0.81369248,  0.79573513,  0.80022447,\n",
       "         0.7979798 ,  0.79910213,  0.79685746,  0.7979798 ,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645]),\n",
       " 'mean_train_score': array([ 0.79722897,  0.79349373,  0.80134686,  0.80209368,  0.80546027,\n",
       "         0.80845708,  0.78563053,  0.78787828,  0.79424503,  0.79012659,\n",
       "         0.78862399,  0.79012826,  0.76317992,  0.77441977,  0.77702834,\n",
       "         0.77815166,  0.77627984,  0.77702778,  0.76766814,  0.77852311,\n",
       "         0.77890072,  0.78376207,  0.77815166,  0.77440914,  0.80208809,\n",
       "         0.79985097,  0.79087341,  0.79087173,  0.79236538,  0.79349037,\n",
       "         0.79424167,  0.78825365,  0.7871309 ,  0.79049916,  0.79386295,\n",
       "         0.78451113,  0.78301972,  0.78301413,  0.78675664,  0.78039717,\n",
       "         0.78525964,  0.7878794 ,  0.78114287,  0.78413688,  0.78263988,\n",
       "         0.7818897 ,  0.78675664,  0.78076862,  0.79498626,  0.79610902,\n",
       "         0.79274075,  0.79386463,  0.79386351,  0.79311612,  0.7893764 ,\n",
       "         0.7893764 ,  0.7893764 ,  0.7893764 ,  0.7893764 ,  0.7893764 ,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.84062592,  0.83239854,  0.84399475,\n",
       "         0.84586544,  0.84511862,  0.84437179,  0.79910526,  0.79686087,\n",
       "         0.81219456,  0.80882573,  0.81631132,  0.81107292,  0.77440914,\n",
       "         0.77590839,  0.78376543,  0.77889624,  0.77553413,  0.78189417,\n",
       "         0.78114623,  0.78825365,  0.77777852,  0.77665633,  0.78488874,\n",
       "         0.77702946,  0.8503559 ,  0.8503559 ,  0.84698484,  0.8469882 ,\n",
       "         0.84623914,  0.8488561 ,  0.80807891,  0.79835173,  0.812194  ,\n",
       "         0.81518801,  0.81107348,  0.81107348,  0.7747806 ,  0.78076862,\n",
       "         0.78189305,  0.78338335,  0.78900215,  0.78264267,  0.78675664,\n",
       "         0.78489098,  0.78376263,  0.78675664,  0.7886279 ,  0.78413688,\n",
       "         0.85260141,  0.84847849,  0.85297398,  0.85446987,  0.853346  ,\n",
       "         0.85634113,  0.80920055,  0.80808171,  0.80770354,  0.80845204,\n",
       "         0.80770354,  0.80770354,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.83763751,\n",
       "         0.84848353,  0.84698372,  0.84474213,  0.84623858,  0.84773502,\n",
       "         0.78226786,  0.80695951,  0.81032442,  0.81032554,  0.81518801,\n",
       "         0.81518857,  0.7886251 ,  0.78750067,  0.77852535,  0.78002012,\n",
       "         0.77964866,  0.77964866,  0.77852815,  0.77141233,  0.78338446,\n",
       "         0.77366232,  0.77216643,  0.77852591,  0.85035199,  0.8462397 ,\n",
       "         0.85184787,  0.85409394,  0.8525975 ,  0.85259526,  0.80508769,\n",
       "         0.8077013 ,  0.80845316,  0.81069811,  0.81107124,  0.81107516,\n",
       "         0.78264267,  0.77927385,  0.78675664,  0.78600814,  0.78601318,\n",
       "         0.78750515,  0.77964587,  0.78825365,  0.78750515,  0.78488539,\n",
       "         0.78338838,  0.7751582 ,  0.85447043,  0.85409506,  0.85596576,\n",
       "         0.85858776,  0.85559095,  0.85708851,  0.81069755,  0.80920055,\n",
       "         0.80882629,  0.80658358,  0.80882629,  0.80882629,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664,  0.78675664,  0.78675664,  0.78675664,  0.78675664,\n",
       "         0.78675664]),\n",
       " 'param_max_depth': masked_array(data = [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
       "  2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6\n",
       "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
       "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_max_features': masked_array(data = [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 3 3\n",
       "  3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 3 3 3 3\n",
       "  3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_samples_leaf': masked_array(data = [10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100 100 100\n",
       "  100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100 100\n",
       "  100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100\n",
       "  100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100\n",
       "  100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100\n",
       "  100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70\n",
       "  100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70\n",
       "  70 100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70\n",
       "  70 70 100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70\n",
       "  70 70 70 100 100 100 100 100 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_warm_start': masked_array(data = [0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
       "  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
       "  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1}),\n",
       " 'rank_test_score': array([ 67, 175,  48,  76, 128,  38, 191, 154, 181, 191,  62, 187, 213,\n",
       "        168, 201, 175, 187, 175, 204, 207, 207, 158, 207, 181, 128, 133,\n",
       "         76,  67, 143,  55,  67, 158, 147, 154, 168,  76, 147, 158, 147,\n",
       "        204,  87,  83, 133, 143, 168, 139,  87, 175, 154, 139, 158, 175,\n",
       "        168, 175, 158, 158, 158, 158, 158, 158,  87,  87,  87,  87,  87,\n",
       "         87,  87,  87,  87,  87,  87,  87,  29,  15,   9,  27,  15,   9,\n",
       "         83,  67,  43,  55,  62, 139, 207, 207, 168, 181, 201, 212, 133,\n",
       "         87, 197, 204, 181, 194,   1,  15,   5,   3,   5,   5,  76,  73,\n",
       "         55,  83,  62,  54, 168, 168, 187, 201,  83, 181,  87, 191, 154,\n",
       "         87,  76, 128,  29,  15,  36,  29,   5,  25,  67,  40,  43,  48,\n",
       "         48,  43,  87,  87,  87,  87,  87,  87,  87,  87,  87,  87,  87,\n",
       "         87,  34,  15,  15,  15,  15,   4, 128,  76,  55,  37,  55,  40,\n",
       "         73, 143, 197, 133, 147, 197, 213, 186, 194, 216, 194, 213,   2,\n",
       "         29,  15,  12,  34,  15,  67,  62,  48,  55,  55,  62, 133, 197,\n",
       "        139, 143, 147,  76, 187,  73, 128, 133, 147, 147,  27,  29,  12,\n",
       "         25,  12,   9,  53,  39,  43,  40,  48,  43,  87,  87,  87,  87,\n",
       "         87,  87,  87,  87,  87,  87,  87,  87], dtype=int32),\n",
       " 'split0_test_score': array([ 0.79372197,  0.77578475,  0.77578475,  0.77130045,  0.77578475,\n",
       "         0.8206278 ,  0.75336323,  0.76681614,  0.76681614,  0.77130045,\n",
       "         0.80269058,  0.77130045,  0.78475336,  0.80717489,  0.76233184,\n",
       "         0.79372197,  0.78475336,  0.77578475,  0.72197309,  0.76681614,\n",
       "         0.75784753,  0.76681614,  0.76681614,  0.78475336,  0.77578475,\n",
       "         0.78923767,  0.79820628,  0.79372197,  0.80269058,  0.79820628,\n",
       "         0.80269058,  0.76681614,  0.78026906,  0.77578475,  0.77578475,\n",
       "         0.79372197,  0.79820628,  0.78475336,  0.79820628,  0.78026906,\n",
       "         0.79372197,  0.80717489,  0.79820628,  0.79820628,  0.79372197,\n",
       "         0.79372197,  0.79820628,  0.79372197,  0.77578475,  0.76681614,\n",
       "         0.76681614,  0.76681614,  0.76681614,  0.76681614,  0.76681614,\n",
       "         0.76681614,  0.76681614,  0.76681614,  0.76681614,  0.76681614,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.78923767,  0.79372197,  0.80717489,\n",
       "         0.79820628,  0.80717489,  0.79372197,  0.80269058,  0.79372197,\n",
       "         0.80717489,  0.78026906,  0.79372197,  0.76233184,  0.74439462,\n",
       "         0.74439462,  0.78923767,  0.78475336,  0.75336323,  0.76681614,\n",
       "         0.80717489,  0.79820628,  0.76681614,  0.75784753,  0.76681614,\n",
       "         0.76233184,  0.81165919,  0.80269058,  0.80269058,  0.81165919,\n",
       "         0.80717489,  0.81165919,  0.78026906,  0.77130045,  0.78923767,\n",
       "         0.78475336,  0.78026906,  0.78923767,  0.78026906,  0.78475336,\n",
       "         0.79372197,  0.78026906,  0.80269058,  0.78475336,  0.79820628,\n",
       "         0.77130045,  0.79820628,  0.79820628,  0.80717489,  0.79372197,\n",
       "         0.77578475,  0.80717489,  0.78026906,  0.80717489,  0.80269058,\n",
       "         0.80269058,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.80717489,\n",
       "         0.78923767,  0.80717489,  0.80269058,  0.78026906,  0.80717489,\n",
       "         0.78026906,  0.79372197,  0.77578475,  0.8206278 ,  0.80269058,\n",
       "         0.79372197,  0.79820628,  0.78475336,  0.76233184,  0.78026906,\n",
       "         0.81165919,  0.76681614,  0.76233184,  0.77578475,  0.76233184,\n",
       "         0.74887892,  0.77130045,  0.74887892,  0.80717489,  0.79372197,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.8161435 ,  0.78475336,\n",
       "         0.80269058,  0.78475336,  0.78923767,  0.78475336,  0.79820628,\n",
       "         0.78475336,  0.75336323,  0.79820628,  0.79820628,  0.80717489,\n",
       "         0.79820628,  0.78475336,  0.79820628,  0.80269058,  0.79372197,\n",
       "         0.79820628,  0.79820628,  0.80717489,  0.79820628,  0.80717489,\n",
       "         0.79820628,  0.80269058,  0.80717489,  0.78475336,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.79820628,\n",
       "         0.79820628]),\n",
       " 'split0_train_score': array([ 0.77844311,  0.79341317,  0.80538922,  0.79491018,  0.80389222,\n",
       "         0.80389222,  0.76497006,  0.79491018,  0.79341317,  0.8008982 ,\n",
       "         0.78443114,  0.79640719,  0.7739521 ,  0.78592814,  0.78143713,\n",
       "         0.78293413,  0.7739521 ,  0.76796407,  0.72904192,  0.79341317,\n",
       "         0.78742515,  0.79341317,  0.79341317,  0.7739521 ,  0.80838323,\n",
       "         0.81586826,  0.78892216,  0.78892216,  0.79191617,  0.78592814,\n",
       "         0.80389222,  0.78892216,  0.77844311,  0.79640719,  0.78892216,\n",
       "         0.76946108,  0.78293413,  0.7739521 ,  0.78293413,  0.77694611,\n",
       "         0.77694611,  0.79341317,  0.7739521 ,  0.78293413,  0.77694611,\n",
       "         0.77994012,  0.78293413,  0.77095808,  0.80239521,  0.79491018,\n",
       "         0.79640719,  0.7994012 ,  0.79640719,  0.79640719,  0.79341317,\n",
       "         0.79341317,  0.79341317,  0.79341317,  0.79341317,  0.79341317,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.83383234,  0.82784431,  0.84431138,\n",
       "         0.8502994 ,  0.8502994 ,  0.85329341,  0.82185629,  0.81437126,\n",
       "         0.80538922,  0.80688623,  0.81437126,  0.7994012 ,  0.77694611,\n",
       "         0.78892216,  0.77844311,  0.77245509,  0.77694611,  0.78892216,\n",
       "         0.79640719,  0.78293413,  0.79341317,  0.78143713,  0.79341317,\n",
       "         0.77994012,  0.8502994 ,  0.8502994 ,  0.84131737,  0.8488024 ,\n",
       "         0.8488024 ,  0.84580838,  0.80988024,  0.7994012 ,  0.81437126,\n",
       "         0.81137725,  0.80988024,  0.81437126,  0.77095808,  0.77245509,\n",
       "         0.77245509,  0.7754491 ,  0.79191617,  0.7739521 ,  0.78293413,\n",
       "         0.79041916,  0.78293413,  0.78293413,  0.79041916,  0.77245509,\n",
       "         0.86227545,  0.84580838,  0.85479042,  0.85628743,  0.8502994 ,\n",
       "         0.86227545,  0.80988024,  0.80988024,  0.80688623,  0.80988024,\n",
       "         0.80688623,  0.80688623,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.83532934,\n",
       "         0.86077844,  0.84580838,  0.84431138,  0.84281437,  0.84580838,\n",
       "         0.77095808,  0.81137725,  0.79491018,  0.80538922,  0.81287425,\n",
       "         0.82035928,  0.78742515,  0.77095808,  0.77844311,  0.77245509,\n",
       "         0.78742515,  0.7739521 ,  0.78592814,  0.77694611,  0.79041916,\n",
       "         0.77245509,  0.77095808,  0.77994012,  0.85329341,  0.8488024 ,\n",
       "         0.8488024 ,  0.84580838,  0.8488024 ,  0.8502994 ,  0.80988024,\n",
       "         0.80389222,  0.80988024,  0.81137725,  0.80988024,  0.81437126,\n",
       "         0.7739521 ,  0.76347305,  0.78293413,  0.78293413,  0.78592814,\n",
       "         0.78293413,  0.76646707,  0.78293413,  0.78592814,  0.7754491 ,\n",
       "         0.78293413,  0.76946108,  0.86077844,  0.85628743,  0.85479042,\n",
       "         0.85778443,  0.86077844,  0.85479042,  0.80838323,  0.81137725,\n",
       "         0.80988024,  0.80688623,  0.80988024,  0.80988024,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413,  0.78293413,  0.78293413,  0.78293413,  0.78293413,\n",
       "         0.78293413]),\n",
       " 'split1_test_score': array([ 0.78923767,  0.8206278 ,  0.85650224,  0.82511211,  0.8161435 ,\n",
       "         0.82959641,  0.8206278 ,  0.83408072,  0.8161435 ,  0.80717489,\n",
       "         0.8206278 ,  0.80717489,  0.76233184,  0.8206278 ,  0.80269058,\n",
       "         0.80269058,  0.80269058,  0.8206278 ,  0.8206278 ,  0.76233184,\n",
       "         0.80269058,  0.80717489,  0.79820628,  0.80717489,  0.8161435 ,\n",
       "         0.80717489,  0.8206278 ,  0.83408072,  0.8206278 ,  0.8206278 ,\n",
       "         0.8161435 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.80269058,  0.8206278 ,  0.78923767,\n",
       "         0.82511211,  0.8206278 ,  0.81165919,  0.80269058,  0.78923767,\n",
       "         0.8206278 ,  0.8206278 ,  0.78475336,  0.8206278 ,  0.8206278 ,\n",
       "         0.82511211,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.85650224,  0.86995516,  0.86547085,\n",
       "         0.86098655,  0.86547085,  0.86098655,  0.78026906,  0.83408072,\n",
       "         0.83408072,  0.83408072,  0.83408072,  0.81165919,  0.80269058,\n",
       "         0.81165919,  0.81165919,  0.78923767,  0.80717489,  0.78923767,\n",
       "         0.79820628,  0.8206278 ,  0.80717489,  0.80269058,  0.80717489,\n",
       "         0.80717489,  0.88340807,  0.85650224,  0.87443946,  0.87892377,\n",
       "         0.86547085,  0.87443946,  0.83856502,  0.85201794,  0.83856502,\n",
       "         0.83856502,  0.83856502,  0.84304933,  0.80717489,  0.78923767,\n",
       "         0.78923767,  0.78923767,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.79372197,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.86098655,  0.86995516,  0.87892377,  0.86547085,  0.88340807,\n",
       "         0.86995516,  0.85201794,  0.84753363,  0.85650224,  0.85201794,\n",
       "         0.85650224,  0.85650224,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.85201794,\n",
       "         0.85650224,  0.85201794,  0.86995516,  0.86995516,  0.86547085,\n",
       "         0.81165919,  0.82959641,  0.84753363,  0.83856502,  0.83408072,\n",
       "         0.83856502,  0.8206278 ,  0.8206278 ,  0.80717489,  0.8206278 ,\n",
       "         0.80717489,  0.80717489,  0.77578475,  0.80269058,  0.80717489,\n",
       "         0.79372197,  0.79820628,  0.80717489,  0.87892377,  0.86098655,\n",
       "         0.87443946,  0.88340807,  0.87443946,  0.87892377,  0.82959641,\n",
       "         0.80269058,  0.85650224,  0.84304933,  0.83408072,  0.82959641,\n",
       "         0.8206278 ,  0.80717489,  0.79372197,  0.80269058,  0.8206278 ,\n",
       "         0.82959641,  0.78026906,  0.8206278 ,  0.81165919,  0.8161435 ,\n",
       "         0.79820628,  0.8206278 ,  0.87443946,  0.86098655,  0.87443946,\n",
       "         0.87443946,  0.87892377,  0.87443946,  0.84304933,  0.86547085,\n",
       "         0.85650224,  0.85201794,  0.85201794,  0.85650224,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,  0.8206278 ,\n",
       "         0.8206278 ]),\n",
       " 'split1_train_score': array([ 0.7739521 ,  0.7754491 ,  0.79191617,  0.79041916,  0.76946108,\n",
       "         0.79790419,  0.7754491 ,  0.77844311,  0.77844311,  0.76047904,\n",
       "         0.76946108,  0.7739521 ,  0.74251497,  0.7754491 ,  0.76347305,\n",
       "         0.77095808,  0.76646707,  0.7754491 ,  0.76646707,  0.74700599,\n",
       "         0.76197605,  0.76646707,  0.76197605,  0.76197605,  0.7754491 ,\n",
       "         0.76497006,  0.78143713,  0.78293413,  0.7754491 ,  0.77994012,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.76946108,  0.7754491 ,  0.76347305,\n",
       "         0.7754491 ,  0.7754491 ,  0.76197605,  0.76497006,  0.76497006,\n",
       "         0.7754491 ,  0.7754491 ,  0.76347305,  0.7754491 ,  0.78592814,\n",
       "         0.7754491 ,  0.77694611,  0.77694611,  0.77694611,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.8248503 ,  0.81886228,  0.82634731,\n",
       "         0.82934132,  0.82335329,  0.82335329,  0.76347305,  0.77844311,\n",
       "         0.79491018,  0.78293413,  0.8008982 ,  0.8008982 ,  0.76197605,\n",
       "         0.76796407,  0.76497006,  0.76497006,  0.76497006,  0.76497006,\n",
       "         0.76497006,  0.78143713,  0.76197605,  0.76646707,  0.76646707,\n",
       "         0.76497006,  0.83233533,  0.83682635,  0.83233533,  0.82934132,\n",
       "         0.82934132,  0.83532934,  0.78742515,  0.78293413,  0.79191617,\n",
       "         0.79790419,  0.79341317,  0.79041916,  0.76497006,  0.76497006,\n",
       "         0.76497006,  0.76497006,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.76347305,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.83982036,  0.83383234,  0.85179641,  0.84580838,  0.84431138,\n",
       "         0.84131737,  0.78592814,  0.79640719,  0.78592814,  0.78592814,\n",
       "         0.78443114,  0.78742515,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.82784431,\n",
       "         0.82035928,  0.8248503 ,  0.82335329,  0.83233533,  0.83233533,\n",
       "         0.76946108,  0.78293413,  0.7994012 ,  0.79191617,  0.7994012 ,\n",
       "         0.79341317,  0.7754491 ,  0.7754491 ,  0.76946108,  0.7754491 ,\n",
       "         0.76497006,  0.76646707,  0.75898204,  0.76646707,  0.76047904,\n",
       "         0.76347305,  0.76646707,  0.76646707,  0.82634731,  0.83083832,\n",
       "         0.83682635,  0.8502994 ,  0.84131737,  0.83682635,  0.78143713,\n",
       "         0.77694611,  0.78892216,  0.78892216,  0.79041916,  0.79491018,\n",
       "         0.7754491 ,  0.77095808,  0.76497006,  0.76646707,  0.7754491 ,\n",
       "         0.77844311,  0.76347305,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.76197605,  0.7754491 ,  0.83982036,  0.83832335,  0.85479042,\n",
       "         0.85778443,  0.84580838,  0.85329341,  0.79640719,  0.78742515,\n",
       "         0.78742515,  0.79041916,  0.78742515,  0.78742515,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,  0.7754491 ,\n",
       "         0.7754491 ]),\n",
       " 'split2_test_score': array([ 0.78026906,  0.74439462,  0.77578475,  0.76233184,  0.77130045,\n",
       "         0.76681614,  0.73991031,  0.74439462,  0.75784753,  0.74439462,\n",
       "         0.74887892,  0.75336323,  0.72197309,  0.74439462,  0.74887892,\n",
       "         0.74887892,  0.74887892,  0.74439462,  0.73991031,  0.74887892,\n",
       "         0.74439462,  0.74887892,  0.74439462,  0.74439462,  0.73991031,\n",
       "         0.74439462,  0.74439462,  0.73991031,  0.73991031,  0.76233184,\n",
       "         0.75784753,  0.73991031,  0.73542601,  0.73542601,  0.74439462,\n",
       "         0.75336323,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73542601,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.74887892,  0.73991031,  0.73991031,  0.73991031,  0.76681614,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.77130045,  0.76233184,  0.76233184,\n",
       "         0.75784753,  0.75336323,  0.78026906,  0.76233184,  0.75784753,\n",
       "         0.75336323,  0.77130045,  0.74887892,  0.76233184,  0.75784753,\n",
       "         0.74887892,  0.74887892,  0.73991031,  0.74887892,  0.73991031,\n",
       "         0.74439462,  0.73991031,  0.74887892,  0.74439462,  0.77130045,\n",
       "         0.74887892,  0.78475336,  0.75784753,  0.76681614,  0.78026906,\n",
       "         0.76681614,  0.75784753,  0.74439462,  0.73542601,  0.75336323,\n",
       "         0.73991031,  0.75784753,  0.75784753,  0.73542601,  0.74887892,\n",
       "         0.74439462,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.77578475,  0.75784753,  0.76681614,  0.77130045,  0.78026906,\n",
       "         0.77130045,  0.73542601,  0.75784753,  0.75784753,  0.75784753,\n",
       "         0.75336323,  0.75784753,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.77130045,\n",
       "         0.77578475,  0.78026906,  0.76233184,  0.77130045,  0.77578475,\n",
       "         0.73991031,  0.74887892,  0.76681614,  0.76233184,  0.75784753,\n",
       "         0.77578475,  0.75784753,  0.74887892,  0.74887892,  0.74887892,\n",
       "         0.74887892,  0.74887892,  0.75784753,  0.7309417 ,  0.74887892,\n",
       "         0.74887892,  0.74439462,  0.74887892,  0.78475336,  0.76681614,\n",
       "         0.76681614,  0.76233184,  0.75784753,  0.74439462,  0.74439462,\n",
       "         0.76233184,  0.75784753,  0.75784753,  0.76233184,  0.75784753,\n",
       "         0.74887892,  0.73991031,  0.75336323,  0.73991031,  0.73542601,\n",
       "         0.73991031,  0.73991031,  0.75336323,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.74439462,  0.76681614,  0.79372197,  0.77578475,\n",
       "         0.78026906,  0.76681614,  0.78026906,  0.75784753,  0.75784753,\n",
       "         0.75784753,  0.75336323,  0.75784753,  0.75784753,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031,  0.73991031,  0.73991031,  0.73991031,  0.73991031,\n",
       "         0.73991031]),\n",
       " 'split2_train_score': array([ 0.83233533,  0.82035928,  0.80688623,  0.81736527,  0.83832335,\n",
       "         0.82934132,  0.80688623,  0.78892216,  0.82784431,  0.81736527,\n",
       "         0.80389222,  0.81287425,  0.75299401,  0.78592814,  0.78293413,\n",
       "         0.77994012,  0.78443114,  0.78293413,  0.78443114,  0.78742515,\n",
       "         0.78892216,  0.78742515,  0.77844311,  0.78293413,  0.80389222,\n",
       "         0.82035928,  0.80688623,  0.8008982 ,  0.80239521,  0.81437126,\n",
       "         0.81137725,  0.80239521,  0.80838323,  0.80389222,  0.81287425,\n",
       "         0.80688623,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.79640719,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.78143713,  0.80239521,  0.80239521,  0.80538922,  0.80688623,\n",
       "         0.80239521,  0.80538922,  0.80538922,  0.80538922,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.85628743,  0.85179641,  0.85928144,\n",
       "         0.85628743,  0.86377246,  0.86227545,  0.82035928,  0.80688623,\n",
       "         0.83233533,  0.82784431,  0.83383234,  0.83083832,  0.77994012,\n",
       "         0.7739521 ,  0.81287425,  0.78892216,  0.78742515,  0.79491018,\n",
       "         0.78592814,  0.80239521,  0.77994012,  0.78443114,  0.80239521,\n",
       "         0.78592814,  0.86976048,  0.86526946,  0.85778443,  0.86227545,\n",
       "         0.85778443,  0.85778443,  0.82185629,  0.80688623,  0.8248503 ,\n",
       "         0.83383234,  0.82934132,  0.82784431,  0.77694611,  0.7994012 ,\n",
       "         0.80838323,  0.79341317,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.85928144,  0.8488024 ,  0.85179641,  0.85928144,  0.85928144,\n",
       "         0.86526946,  0.8248503 ,  0.82035928,  0.82185629,  0.82185629,\n",
       "         0.82335329,  0.82035928,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.85479042,\n",
       "         0.86077844,  0.85778443,  0.86227545,  0.85928144,  0.86077844,\n",
       "         0.80838323,  0.82934132,  0.83383234,  0.83383234,  0.83083832,\n",
       "         0.83083832,  0.79790419,  0.80538922,  0.78592814,  0.78592814,\n",
       "         0.78742515,  0.7994012 ,  0.79640719,  0.75598802,  0.78592814,\n",
       "         0.78443114,  0.77994012,  0.78892216,  0.86227545,  0.85778443,\n",
       "         0.85928144,  0.85928144,  0.86077844,  0.85778443,  0.82335329,\n",
       "         0.82784431,  0.82185629,  0.82784431,  0.82634731,  0.82784431,\n",
       "         0.80239521,  0.80239521,  0.81287425,  0.80838323,  0.80988024,\n",
       "         0.80239521,  0.80239521,  0.80838323,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.77844311,  0.86227545,  0.86377246,  0.85479042,\n",
       "         0.86526946,  0.85479042,  0.86077844,  0.82185629,  0.82185629,\n",
       "         0.82185629,  0.82035928,  0.82185629,  0.82185629,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521,  0.80239521,  0.80239521,  0.80239521,  0.80239521,\n",
       "         0.80239521]),\n",
       " 'split3_test_score': array([ 0.8018018 ,  0.76576577,  0.77927928,  0.7972973 ,  0.77927928,\n",
       "         0.79279279,  0.77477477,  0.77477477,  0.76126126,  0.76576577,\n",
       "         0.7972973 ,  0.76126126,  0.78828829,  0.73873874,  0.76126126,\n",
       "         0.76126126,  0.75675676,  0.76576577,  0.78828829,  0.78828829,\n",
       "         0.76126126,  0.79279279,  0.75675676,  0.76576577,  0.81081081,\n",
       "         0.7972973 ,  0.79279279,  0.7972973 ,  0.76576577,  0.79279279,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.77027027,\n",
       "         0.78828829,  0.76576577,  0.78828829,  0.76576577,  0.76126126,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.77027027,  0.78828829,  0.78828829,  0.78378378,  0.77927928,\n",
       "         0.78378378,  0.77927928,  0.78378378,  0.77927928,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.81531532,  0.81981982,  0.81981982,\n",
       "         0.81981982,  0.81981982,  0.81981982,  0.80630631,  0.77927928,\n",
       "         0.7972973 ,  0.78828829,  0.79279279,  0.7972973 ,  0.76126126,\n",
       "         0.76126126,  0.76126126,  0.78828829,  0.76576577,  0.76576577,\n",
       "         0.78828829,  0.78828829,  0.75675676,  0.76576577,  0.75675676,\n",
       "         0.76576577,  0.81081081,  0.82882883,  0.81531532,  0.80630631,\n",
       "         0.81981982,  0.81531532,  0.79279279,  0.8018018 ,  0.79279279,\n",
       "         0.78828829,  0.79279279,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.76576577,  0.76576577,  0.78828829,  0.75675676,  0.78828829,\n",
       "         0.75675676,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.81981982,  0.81081081,  0.79279279,  0.78828829,  0.79279279,\n",
       "         0.7972973 ,  0.7972973 ,  0.81081081,  0.7972973 ,  0.7972973 ,\n",
       "         0.7972973 ,  0.7972973 ,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.7972973 ,\n",
       "         0.82432432,  0.80630631,  0.81081081,  0.82432432,  0.81531532,\n",
       "         0.81081081,  0.78378378,  0.78378378,  0.79279279,  0.77927928,\n",
       "         0.78828829,  0.78378378,  0.77477477,  0.76126126,  0.78828829,\n",
       "         0.75675676,  0.75675676,  0.76126126,  0.78828829,  0.76576577,\n",
       "         0.76126126,  0.77027027,  0.75225225,  0.81531532,  0.81081081,\n",
       "         0.80630631,  0.80630631,  0.7972973 ,  0.80630631,  0.80630631,\n",
       "         0.8018018 ,  0.78828829,  0.78378378,  0.79279279,  0.78378378,\n",
       "         0.78378378,  0.77927928,  0.78828829,  0.78828829,  0.76126126,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.76126126,  0.78828829,  0.77927928,  0.79279279,\n",
       "         0.78828829,  0.8018018 ,  0.79279279,  0.7972973 ,  0.7972973 ,\n",
       "         0.7972973 ,  0.81081081,  0.7972973 ,  0.7972973 ,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829,  0.78828829,  0.78828829,  0.78828829,  0.78828829,\n",
       "         0.78828829]),\n",
       " 'split3_train_score': array([ 0.80418535,  0.78475336,  0.80119581,  0.80568012,  0.81016442,\n",
       "         0.80269058,  0.79521674,  0.78923767,  0.77727952,  0.78176383,\n",
       "         0.79671151,  0.77727952,  0.78325859,  0.75037369,  0.78026906,\n",
       "         0.77877429,  0.78026906,  0.78176383,  0.79073244,  0.78624813,\n",
       "         0.77727952,  0.7877429 ,  0.77877429,  0.77877429,  0.8206278 ,\n",
       "         0.79820628,  0.78624813,  0.79073244,  0.79970105,  0.79372197,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.79820628,\n",
       "         0.78624813,  0.77130045,  0.78624813,  0.78624813,  0.77877429,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.79073244,  0.78624813,  0.78624813,  0.79671151,  0.79671151,\n",
       "         0.79671151,  0.79372197,  0.79671151,  0.79372197,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.84753363,  0.83109118,  0.84603886,\n",
       "         0.84753363,  0.84304933,  0.83856502,  0.79073244,  0.7877429 ,\n",
       "         0.8161435 ,  0.81763827,  0.8161435 ,  0.81315396,  0.77877429,\n",
       "         0.77279522,  0.77877429,  0.78923767,  0.77279522,  0.77877429,\n",
       "         0.77727952,  0.78624813,  0.77578475,  0.77428999,  0.77727952,\n",
       "         0.77727952,  0.8490284 ,  0.8490284 ,  0.85650224,  0.84753363,\n",
       "         0.8490284 ,  0.85650224,  0.81315396,  0.80418535,  0.81763827,\n",
       "         0.81763827,  0.81165919,  0.81165919,  0.78624813,  0.78624813,\n",
       "         0.78176383,  0.79970105,  0.78624813,  0.77877429,  0.78624813,\n",
       "         0.77130045,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.8490284 ,  0.86547085,  0.85351271,  0.85650224,  0.85949178,\n",
       "         0.85650224,  0.8161435 ,  0.80568012,  0.8161435 ,  0.8161435 ,\n",
       "         0.8161435 ,  0.8161435 ,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.83258595,\n",
       "         0.85201794,  0.85949178,  0.8490284 ,  0.85052317,  0.85201794,\n",
       "         0.78026906,  0.80418535,  0.81315396,  0.81016442,  0.81763827,\n",
       "         0.8161435 ,  0.79372197,  0.79820628,  0.78026906,  0.78624813,\n",
       "         0.77877429,  0.77877429,  0.77279522,  0.78624813,  0.79671151,\n",
       "         0.77428999,  0.77130045,  0.77877429,  0.85949178,  0.84753363,\n",
       "         0.86248132,  0.86098655,  0.85949178,  0.86547085,  0.80568012,\n",
       "         0.82212257,  0.81315396,  0.81464873,  0.81763827,  0.80717489,\n",
       "         0.77877429,  0.78026906,  0.78624813,  0.78624813,  0.77279522,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.77727952,  0.85500747,  0.85799701,  0.85949178,\n",
       "         0.85351271,  0.86098655,  0.85949178,  0.8161435 ,  0.8161435 ,\n",
       "         0.8161435 ,  0.80866966,  0.8161435 ,  0.8161435 ,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813,  0.78624813,  0.78624813,  0.78624813,  0.78624813,\n",
       "         0.78624813]),\n",
       " 'std_fit_time': array([ 0.00240803,  0.00400285,  0.00623764,  0.01752183,  0.00602275,\n",
       "         0.00663   ,  0.00155257,  0.00248013,  0.00245121,  0.00209794,\n",
       "         0.00423649,  0.00985223,  0.00209783,  0.00111454,  0.00419197,\n",
       "         0.00907921,  0.00718208,  0.00377628,  0.00120459,  0.0011014 ,\n",
       "         0.00163497,  0.00200952,  0.0066011 ,  0.00373927,  0.00185867,\n",
       "         0.00113503,  0.00157153,  0.00228818,  0.00507949,  0.00208362,\n",
       "         0.00206507,  0.000564  ,  0.0024093 ,  0.00051675,  0.005672  ,\n",
       "         0.00407368,  0.00262387,  0.00015698,  0.00303439,  0.0004993 ,\n",
       "         0.00686072,  0.00474776,  0.00174039,  0.00138666,  0.00251133,\n",
       "         0.00434757,  0.00507885,  0.00374384,  0.00101969,  0.00239458,\n",
       "         0.0079363 ,  0.00623845,  0.00503964,  0.01343588,  0.00218578,\n",
       "         0.00130864,  0.00050865,  0.00244542,  0.00291615,  0.0041396 ,\n",
       "         0.00199662,  0.00321093,  0.00426621,  0.00338875,  0.00293675,\n",
       "         0.00690942,  0.00207381,  0.00153839,  0.00483863,  0.00106407,\n",
       "         0.00741055,  0.00611396,  0.00274429,  0.00175605,  0.00553006,\n",
       "         0.00428116,  0.01219893,  0.00289167,  0.00178498,  0.00120606,\n",
       "         0.00356344,  0.01125109,  0.00326897,  0.00602867,  0.00077843,\n",
       "         0.00192831,  0.0069465 ,  0.01271497,  0.00943104,  0.04373827,\n",
       "         0.0043118 ,  0.0010711 ,  0.0034393 ,  0.00979401,  0.00949131,\n",
       "         0.0072325 ,  0.00153325,  0.00197938,  0.00185363,  0.00200228,\n",
       "         0.00094048,  0.00239578,  0.00082472,  0.00119026,  0.00259721,\n",
       "         0.01077516,  0.00740063,  0.00328712,  0.00084728,  0.00189535,\n",
       "         0.00277026,  0.00222571,  0.00471007,  0.00290718,  0.00260602,\n",
       "         0.00205747,  0.00155127,  0.00222508,  0.00701412,  0.00456119,\n",
       "         0.00230134,  0.00052145,  0.00530952,  0.00289917,  0.01755064,\n",
       "         0.01258986,  0.00174902,  0.0025958 ,  0.01178014,  0.01410643,\n",
       "         0.00434611,  0.00534572,  0.00215903,  0.00037183,  0.00204936,\n",
       "         0.00353047,  0.00390955,  0.00482594,  0.00159448,  0.00369854,\n",
       "         0.00549869,  0.00242139,  0.00514913,  0.00425947,  0.00138621,\n",
       "         0.00190572,  0.00195306,  0.00355902,  0.00323116,  0.00584652,\n",
       "         0.00174196,  0.00090246,  0.00263207,  0.00157405,  0.00251258,\n",
       "         0.00428263,  0.00059444,  0.00132514,  0.00114242,  0.00226108,\n",
       "         0.00433342,  0.0073734 ,  0.00227129,  0.00147029,  0.0045299 ,\n",
       "         0.0048407 ,  0.00660953,  0.00453594,  0.00140236,  0.00086008,\n",
       "         0.0033316 ,  0.00618056,  0.00513269,  0.00678141,  0.0032137 ,\n",
       "         0.00163895,  0.00164341,  0.00380325,  0.00505497,  0.00489003,\n",
       "         0.00130943,  0.00197165,  0.00305198,  0.00240159,  0.00655502,\n",
       "         0.00512347,  0.00205743,  0.00205782,  0.00132249,  0.00124059,\n",
       "         0.00456002,  0.00188126,  0.00250529,  0.00196289,  0.00719732,\n",
       "         0.00560078,  0.00633288,  0.00734677,  0.00137397,  0.00174382,\n",
       "         0.00340693,  0.00332909,  0.00730682,  0.00491133,  0.00080288,\n",
       "         0.00234935,  0.00574267,  0.00351959,  0.00225463,  0.00574312,\n",
       "         0.00077333,  0.00117308,  0.00411104,  0.00272327,  0.00201498,\n",
       "         0.00436361]),\n",
       " 'std_score_time': array([  3.90517019e-04,   8.28890188e-05,   1.88461857e-03,\n",
       "          2.63759714e-03,   2.13970875e-03,   4.21718776e-04,\n",
       "          4.83941600e-04,   2.24404981e-04,   1.92191766e-03,\n",
       "          8.79333301e-04,   2.20050803e-03,   1.00305284e-03,\n",
       "          5.02502351e-04,   5.32455104e-04,   1.16947660e-03,\n",
       "          1.23531822e-03,   9.07914118e-04,   2.77699120e-03,\n",
       "          1.94712091e-04,   2.61388625e-05,   8.43558767e-04,\n",
       "          9.98390865e-04,   1.02599959e-03,   1.48614110e-03,\n",
       "          3.84087077e-05,   9.70253371e-04,   3.94841521e-05,\n",
       "          6.42031054e-04,   2.18928275e-03,   1.40217536e-03,\n",
       "          1.07754977e-04,   1.09401058e-04,   1.21656960e-03,\n",
       "          6.57338453e-04,   2.26405994e-03,   2.21179720e-03,\n",
       "          1.07479637e-04,   7.99419620e-05,   1.78930720e-03,\n",
       "          6.27050095e-04,   1.46552322e-03,   1.00694581e-03,\n",
       "          1.02224793e-03,   6.76875771e-04,   1.90602399e-03,\n",
       "          1.10741213e-03,   1.89831086e-03,   2.71063747e-03,\n",
       "          1.54993854e-05,   4.38956949e-05,   6.15651353e-04,\n",
       "          1.34743033e-04,   1.04346295e-03,   2.68495113e-03,\n",
       "          5.98800875e-04,   4.15123993e-05,   6.09434685e-05,\n",
       "          9.88913225e-04,   1.47897732e-03,   1.00622668e-04,\n",
       "          5.84287800e-04,   7.82777368e-04,   2.80917944e-03,\n",
       "          1.35569206e-03,   1.15526505e-03,   8.00943388e-05,\n",
       "          4.08998629e-05,   1.14056647e-03,   5.98224389e-04,\n",
       "          2.00337897e-04,   1.97297158e-03,   1.10189758e-04,\n",
       "          1.37259442e-04,   8.89097534e-05,   1.18754922e-03,\n",
       "          8.50044580e-04,   3.05939075e-03,   7.50278920e-04,\n",
       "          3.49222891e-04,   3.05268899e-05,   9.97006934e-04,\n",
       "          2.87190222e-04,   1.27639827e-03,   7.20487620e-04,\n",
       "          2.72619317e-04,   5.75753555e-04,   3.98183381e-04,\n",
       "          1.25040718e-03,   1.75017290e-03,   4.43081631e-03,\n",
       "          7.73551183e-04,   9.38509692e-04,   1.12727450e-03,\n",
       "          1.03526829e-03,   7.52072132e-04,   5.53729190e-04,\n",
       "          3.25779883e-04,   3.31416833e-05,   1.05097006e-03,\n",
       "          1.52643806e-04,   1.17686515e-03,   3.27993718e-04,\n",
       "          2.34993533e-05,   6.83503287e-04,   1.12350049e-03,\n",
       "          9.92094723e-04,   1.37744302e-03,   1.46104669e-03,\n",
       "          9.40438716e-05,   3.58934796e-05,   5.53263820e-04,\n",
       "          2.33284996e-05,   3.64415993e-04,   2.79864068e-03,\n",
       "          3.34332649e-05,   3.06682550e-05,   1.10140994e-03,\n",
       "          1.13544873e-03,   2.95068657e-04,   2.15327101e-03,\n",
       "          4.02424060e-05,   8.14007215e-05,   1.00239798e-03,\n",
       "          4.89450087e-04,   1.07206290e-03,   7.58814960e-04,\n",
       "          2.40904860e-04,   8.67238831e-04,   1.28550050e-03,\n",
       "          1.33740683e-03,   1.64918621e-03,   2.05802362e-03,\n",
       "          1.02988961e-04,   6.02254427e-05,   2.95909501e-03,\n",
       "          1.09978117e-03,   7.81096763e-04,   2.14288900e-03,\n",
       "          4.14467934e-04,   1.35302229e-04,   1.11057907e-03,\n",
       "          1.07611810e-03,   1.12294311e-03,   2.14706115e-04,\n",
       "          1.62443818e-04,   6.45701307e-04,   1.56768635e-04,\n",
       "          8.89891883e-04,   2.45009967e-03,   1.03268052e-03,\n",
       "          2.27695984e-05,   1.43645739e-03,   5.83056922e-04,\n",
       "          1.62084176e-04,   1.87224778e-03,   7.46154043e-04,\n",
       "          1.60662847e-04,   2.56593669e-05,   4.70666246e-04,\n",
       "          1.35721438e-04,   2.04841114e-03,   1.86208314e-03,\n",
       "          2.46973477e-04,   1.32314189e-04,   6.33718453e-04,\n",
       "          4.83323281e-04,   1.54154778e-03,   9.79432410e-04,\n",
       "          3.44836438e-05,   5.18891706e-04,   2.84415353e-05,\n",
       "          2.02122938e-03,   3.16042496e-03,   1.20095120e-03,\n",
       "          3.05213870e-04,   4.23563875e-05,   6.30650661e-05,\n",
       "          2.40926780e-03,   2.29782529e-03,   1.59823525e-03,\n",
       "          4.89911022e-04,   2.49896075e-04,   1.60109541e-03,\n",
       "          3.06073072e-04,   1.41267467e-03,   1.72267468e-03,\n",
       "          1.45279924e-04,   3.77426382e-05,   8.56402390e-05,\n",
       "          5.91195405e-04,   1.24121905e-03,   1.01084748e-03,\n",
       "          4.20061382e-05,   3.86640055e-04,   2.41917384e-03,\n",
       "          1.28400827e-03,   2.44664094e-03,   2.49823645e-03,\n",
       "          4.29316016e-04,   1.20982145e-04,   1.93246862e-05,\n",
       "          1.61886654e-04,   2.44563098e-03,   1.26621907e-03,\n",
       "          1.80593221e-05,   2.09584713e-05,   4.48845392e-04,\n",
       "          8.64656071e-04,   2.28336127e-03,   1.95428019e-03,\n",
       "          6.79805027e-04,   1.00302912e-04,   9.63371040e-04,\n",
       "          1.11222533e-03,   1.25448463e-03,   4.31970862e-04]),\n",
       " 'std_test_score': array([ 0.00777582,  0.02782361,  0.03449116,  0.02449375,  0.017853  ,\n",
       "         0.02466121,  0.03063292,  0.03316018,  0.02368151,  0.02258699,\n",
       "         0.02656985,  0.02058617,  0.02640911,  0.03653063,  0.02028349,\n",
       "         0.02224166,  0.02159814,  0.02782361,  0.03903004,  0.01415506,\n",
       "         0.02181005,  0.02258975,  0.01993936,  0.02320134,  0.03063385,\n",
       "         0.02403468,  0.02780513,  0.03360735,  0.03145739,  0.02080841,\n",
       "         0.02166296,  0.02957656,  0.03043368,  0.03052782,  0.02745005,\n",
       "         0.02395659,  0.03078144,  0.02350889,  0.03078144,  0.01895389,\n",
       "         0.03049895,  0.03240759,  0.02707072,  0.02502086,  0.02197517,\n",
       "         0.02673471,  0.02949222,  0.02146992,  0.02869457,  0.02210799,\n",
       "         0.03094274,  0.02911718,  0.02928303,  0.02911718,  0.02957656,\n",
       "         0.02957656,  0.02957656,  0.02957656,  0.02957656,  0.02957656,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.03205154,  0.03945393,  0.03675877,\n",
       "         0.03727697,  0.03996093,  0.03079896,  0.01781444,  0.02784977,\n",
       "         0.02908058,  0.0242092 ,  0.03015519,  0.02168348,  0.02181005,\n",
       "         0.02678166,  0.02443703,  0.02064999,  0.02301802,  0.01747471,\n",
       "         0.02412131,  0.02949222,  0.0224446 ,  0.0216239 ,  0.0190243 ,\n",
       "         0.02180883,  0.0367222 ,  0.03635331,  0.03877163,  0.0364377 ,\n",
       "         0.03520927,  0.04128626,  0.03369708,  0.04278149,  0.03026793,\n",
       "         0.03494811,  0.02948003,  0.0307031 ,  0.02634937,  0.01678072,\n",
       "         0.0197791 ,  0.01867204,  0.02998775,  0.03058878,  0.02949222,\n",
       "         0.03012546,  0.02344032,  0.02949222,  0.03059879,  0.02911809,\n",
       "         0.03545388,  0.03975503,  0.04384915,  0.0355066 ,  0.04042141,\n",
       "         0.03644129,  0.04175484,  0.03370389,  0.03659103,  0.03480392,\n",
       "         0.03785182,  0.03659103,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02914887,\n",
       "         0.03148234,  0.02581479,  0.03846822,  0.03930338,  0.03220099,\n",
       "         0.02929004,  0.02877006,  0.03179625,  0.0288772 ,  0.02831641,\n",
       "         0.02371129,  0.0228031 ,  0.02574564,  0.02216458,  0.02554012,\n",
       "         0.02848477,  0.0224446 ,  0.00683391,  0.02686146,  0.02180883,\n",
       "         0.01835094,  0.01904118,  0.0248049 ,  0.03498775,  0.03435359,\n",
       "         0.03926991,  0.04414754,  0.04225842,  0.04771717,  0.03137742,\n",
       "         0.01735822,  0.03641714,  0.03099472,  0.02597246,  0.02592332,\n",
       "         0.02538475,  0.02575273,  0.01770007,  0.02502086,  0.03437136,\n",
       "         0.03220161,  0.01949335,  0.02425465,  0.02770085,  0.02780445,\n",
       "         0.02416552,  0.02999247,  0.04030913,  0.03135649,  0.03743581,\n",
       "         0.03758544,  0.04097806,  0.03636815,  0.03082772,  0.0402085 ,\n",
       "         0.03659103,  0.03670604,  0.03480392,  0.03659103,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222,  0.02949222,  0.02949222,  0.02949222,  0.02949222,\n",
       "         0.02949222]),\n",
       " 'std_train_score': array([ 0.0233215 ,  0.01676132,  0.00583065,  0.01041611,  0.02449751,\n",
       "         0.01226382,  0.01638762,  0.00594575,  0.02041527,  0.02125374,\n",
       "         0.01307023,  0.01568091,  0.01620174,  0.0145272 ,  0.00788295,\n",
       "         0.0044217 ,  0.00678355,  0.00595731,  0.02401243,  0.01839813,\n",
       "         0.01074905,  0.01026555,  0.01112471,  0.00785049,  0.01655476,\n",
       "         0.02177457,  0.00962619,  0.00646831,  0.01049728,  0.01300828,\n",
       "         0.01417584,  0.00959699,  0.01288781,  0.01071044,  0.01363612,\n",
       "         0.01425032,  0.0119381 ,  0.01276608,  0.00983991,  0.01400788,\n",
       "         0.01072341,  0.0080703 ,  0.01497331,  0.01329133,  0.01367419,\n",
       "         0.0055606 ,  0.00983991,  0.01494254,  0.01170247,  0.0074431 ,\n",
       "         0.01026425,  0.01060338,  0.0104118 ,  0.01028709,  0.00986839,\n",
       "         0.00986839,  0.00986839,  0.00986839,  0.00986839,  0.00986839,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.01212458,  0.0120619 ,  0.01171958,\n",
       "         0.01005121,  0.01460152,  0.01479554,  0.02402655,  0.01440028,\n",
       "         0.01384113,  0.0166846 ,  0.01170835,  0.01259718,  0.00725714,\n",
       "         0.00784202,  0.01770472,  0.01052249,  0.00810079,  0.01134646,\n",
       "         0.01153672,  0.00834817,  0.01121169,  0.00694126,  0.01393198,\n",
       "         0.00763463,  0.01325749,  0.01008995,  0.01065294,  0.01171219,\n",
       "         0.01040649,  0.00908901,  0.01270231,  0.00929614,  0.01230602,\n",
       "         0.01291188,  0.01272171,  0.01340783,  0.00785894,  0.01319003,\n",
       "         0.01641043,  0.01386422,  0.0097357 ,  0.0115369 ,  0.00983991,\n",
       "         0.01235729,  0.01383568,  0.00983991,  0.00964484,  0.01172354,\n",
       "         0.0088647 ,  0.01129695,  0.00126125,  0.00513825,  0.00640129,\n",
       "         0.00922863,  0.01444979,  0.00860284,  0.01365988,  0.0136766 ,\n",
       "         0.01464941,  0.0126815 ,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.01025884,\n",
       "         0.01662675,  0.01382368,  0.01399515,  0.00991841,  0.01036022,\n",
       "         0.01563596,  0.0166236 ,  0.01514549,  0.01513165,  0.01124181,\n",
       "         0.01366319,  0.0084724 ,  0.01460743,  0.00591628,  0.0061607 ,\n",
       "         0.00918114,  0.01221815,  0.01404757,  0.01132573,  0.01376795,\n",
       "         0.00744379,  0.00487655,  0.00799311,  0.01423536,  0.00973043,\n",
       "         0.01004053,  0.0062743 ,  0.00800161,  0.01056691,  0.01513523,\n",
       "         0.0198375 ,  0.01209585,  0.01400226,  0.01327037,  0.01192254,\n",
       "         0.0115369 ,  0.0146151 ,  0.01711472,  0.01493323,  0.01462838,\n",
       "         0.00903201,  0.01578261,  0.0122625 ,  0.00963236,  0.0110288 ,\n",
       "         0.01438864,  0.00345805,  0.00888288,  0.0095188 ,  0.00203575,\n",
       "         0.00423356,  0.00617175,  0.00312551,  0.00953607,  0.013108  ,\n",
       "         0.0130618 ,  0.01067124,  0.0130618 ,  0.0130618 ,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991,  0.00983991,  0.00983991,  0.00983991,  0.00983991,\n",
       "         0.00983991])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_RFC.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_estimator = RandomForestClassifier(max_depth=6,\n",
    "                                  max_features= 3,\n",
    "                                  min_samples_leaf= 10,\n",
    "                                  n_estimators= 50,\n",
    "                                  warm_start= 0)\n",
    "rfc_estimator_fitted = rf_estimator.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Random Forest Classifier @ kaggle - 0.78947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №2 для GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_estimators':[3,10,50,100],\n",
    "       'learning_rate':[0.03,0.3,3],\n",
    "       'max_depth':[2,6,10],\n",
    "       'min_samples_leaf':[10,30,70,100]\n",
    "       }\n",
    "\n",
    "gridSearchGradientBoosting = GridSearchCV(GradientBoostingClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:256: RuntimeWarning: overflow encountered in multiply\n",
      "  * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:256: RuntimeWarning: overflow encountered in multiply\n",
      "  * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:256: RuntimeWarning: overflow encountered in multiply\n",
      "  * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "/Users/Slava-N/anaconda/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py:490: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n"
     ]
    }
   ],
   "source": [
    "param_finder_GBC = gridSearchGradientBoosting.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03,\n",
       " 'max_depth': 6,\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_GBC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_estimator = GradientBoostingClassifier(n_estimators=10, max_depth=6, min_samples_leaf=30, learning_rate=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_estimator_fitted = gb_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single GradientBoostingClassifier @ kaggle - 0.77512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №3 для Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'max_depth':list(range(2,10,1)),\n",
    "       'min_samples_leaf':[10,30,70,100]}\n",
    "\n",
    "gridSearchDecisionTree = GridSearchCV(DecisionTreeClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_DT = gridSearchDecisionTree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_estimator = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_estimator_fitted = dt_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Decision Tree @ kaggle - 0.78469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №4  для SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9]}\n",
    "\n",
    "gridSearchSupportVector = GridSearchCV(LinearSVC(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_SVC = gridSearchSupportVector.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.03}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76233184,  0.78026906,  0.79820628,  0.83333333])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LinearSVC(C=0.03),\n",
    "                         X_train, y_train, groups=None,\n",
    "                        scoring = make_scorer(accuracy_score),\n",
    "                        cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_estimator = LinearSVC(C=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_estimator_fitted = svc_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single LinearSVC @ kaggle - 0.75\n",
    "Самый плохой показатель, в стекинг моделей в любом случае не включаем - отсутствует метод оценки вероятности для предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №5  для LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9]}\n",
    "\n",
    "gridSearchLogisticRegression = GridSearchCV(LogisticRegression(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_LR = gridSearchLogisticRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_estimator = LogisticRegression(C=6)\n",
    "LR_estimator_fitted = LR_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single LogisticRegression @ kaggle - 0.76077\n",
    "Достаточно низкий показатель, в любом случае идет в стеккинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование матрицы предсказаний четырех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# получаем предсказания вероятностей ансамблей на кросс-валидации для обучающей выборки\n",
    "rf_train_pred = cross_val_predict_proba(rf_estimator, X_train, y_train)\n",
    "gb_train_pred = cross_val_predict_proba(gb_estimator, X_train, y_train)\n",
    "dt_train_pred = cross_val_predict_proba(dt_estimator, X_train, y_train)\n",
    "lr_train_pred = cross_val_predict_proba(LR_estimator, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_stack = np.stack([rf_train_pred[:,1], gb_train_pred[:,1], dt_train_pred[:,1],lr_train_pred[:,1]], axis=1)\n",
    "\n",
    "# получаем предсказания ансамблей для тестовой выборки\n",
    "rf_test_pred = rfc_estimator_fitted.predict_proba(X_test)\n",
    "gb_test_pred = gb_estimator_fitted.predict_proba(X_test)\n",
    "dt_test_pred = dt_estimator_fitted.predict_proba(X_test)\n",
    "lr_test_pred = LR_estimator_fitted.predict_proba(X_test)\n",
    "\n",
    "\n",
    "X_test_stack = np.stack([rf_test_pred[:,1], gb_test_pred[:,1],dt_test_pred[:,1],lr_test_pred[:,1]], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем предсказания ансамблей с помощью логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9,15,50]}\n",
    "gridSearchEnsemble = GridSearchCV(LogisticRegression(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.03, 0.3, 0.9, 3, 6, 9, 15, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchEnsemble.fit(X_train_stack, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchEnsemble.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При таком значении модель переобучается. Взято значение 0.5 - дает наилучший результат\n",
    "\n",
    "50 0.7799\n",
    "0.5 0.78794\n",
    "0.03 0.78469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: подобрать гиперпараметры LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=0.7).fit(X_train_stack, y_train)\n",
    "predicted = logreg.predict(X_test_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем фалй для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission_ensemble_3_models_regularization_10.txt', 'w') as out:\n",
    "    out.write('PassengerId,Survived\\n')\n",
    "    for passenger, y in zip(test['PassengerId'], predicted):\n",
    "        out.write('%s,%s\\n' % (passenger, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
