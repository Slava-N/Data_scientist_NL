{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = pd.read_csv('./homework/train.csv')\n",
    "test = pd.read_csv('./homework/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание:\n",
    "1. Подготовка данных\n",
    "2. Импорт библиотек моделей\n",
    "3. Подбор параметров для Random Forest\n",
    "4. Подбор параметров для Gradient Boosting\n",
    "5. Подбор параметров для Decision Tree\n",
    "6. Подбор параметров для SVM\n",
    "7. Подбор параметров для Logistic Regression\n",
    "8. Формирование матрицы предсказаний нескольких моделей\n",
    "9. Объединение предсказаний by Logistic Regression\n",
    "10. Формирование файла для отправки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных\n",
    "\n",
    "\n",
    ".\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем пропуски в данных медианными \n",
    "# значениями факторов на обучающей выборке\n",
    "train_median = train.median()\n",
    "train_imp = train.fillna(train_median)\n",
    "test_imp = test.fillna(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Бинаризуем категориальные признаки\n",
    "CATEGORY_COL = ['Sex', 'Pclass', 'Embarked']\n",
    "train_dummies = pd.get_dummies(train_imp, columns=CATEGORY_COL, drop_first=True)\n",
    "test_dummies = pd.get_dummies(test_imp, columns=CATEGORY_COL, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_male  Pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN         1         0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85         0         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN         0         0   \n",
       "3  35.0      1      0            113803  53.1000  C123         0         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN         1         0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  \n",
       "0         1           0           1  \n",
       "1         0           0           0  \n",
       "2         1           0           1  \n",
       "3         0           0           1  \n",
       "4         1           0           1  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаляем лишние столбцы\n",
    "DROP_COL = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "TARGET_COL = 'Survived'\n",
    "X_train = train_dummies.drop(DROP_COL + [TARGET_COL], axis=1)\n",
    "y_train = train_dummies[TARGET_COL]\n",
    "X_test = test_dummies.drop(DROP_COL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch     Fare  Sex_male  Pclass_2  Pclass_3  Embarked_Q  \\\n",
       "0  22.0      1      0   7.2500         1         0         1           0   \n",
       "1  38.0      1      0  71.2833         0         0         0           0   \n",
       "2  26.0      0      0   7.9250         0         0         1           0   \n",
       "3  35.0      1      0  53.1000         0         0         0           0   \n",
       "4  35.0      0      0   8.0500         1         0         1           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание моделей для стеккинга\n",
    "\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def cross_val_predict_proba(estimator, X_train, y_train):\n",
    "    kfold = KFold(n_splits=4, shuffle=True, random_state=None)\n",
    "    return cross_val_predict(estimator, X_train, y_train, cv=kfold, method='predict_proba')\n",
    "\n",
    "# TODO: подобрать гиперпараметры для ансамблей\n",
    "\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №1 для Random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_estimators':[10,50,100],\n",
    "       'max_features':[3,5,9],\n",
    "       'max_depth':[2,6,10],\n",
    "       'min_samples_leaf':[10,30,70,100],\n",
    "        'warm_start':[0,1]\n",
    "       }\n",
    "\n",
    "gridSearchRandomForest = GridSearchCV(RandomForestClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_RFC = gridSearchRandomForest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 50,\n",
       " 'warm_start': 0}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_RFC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.02326661,  0.01348603,  0.07285047,  0.07578194,  0.13200665,\n",
       "         0.14666975,  0.01998466,  0.00867754,  0.07117414,  0.07860249,\n",
       "         0.16326696,  0.14182955,  0.01558161,  0.01206535,  0.07394183,\n",
       "         0.07439798,  0.14010257,  0.14336246,  0.01562983,  0.01526129,\n",
       "         0.06981927,  0.06912053,  0.1439454 ,  0.13973749,  0.01826966,\n",
       "         0.00868845,  0.07711422,  0.07470196,  0.14514339,  0.13849467,\n",
       "         0.01953113,  0.01562983,  0.07173198,  0.06276095,  0.13650841,\n",
       "         0.14161628,  0.01562524,  0.0156256 ,  0.09163487,  0.07203299,\n",
       "         0.14526123,  0.14978099,  0.01562995,  0.02006257,  0.06406635,\n",
       "         0.06260234,  0.12648255,  0.13060087,  0.01562101,  0.01191688,\n",
       "         0.08512491,  0.09656799,  0.2060762 ,  0.17655921,  0.01987559,\n",
       "         0.02359712,  0.07812709,  0.07319051,  0.2104131 ,  0.19691771,\n",
       "         0.03227127,  0.03577679,  0.08492017,  0.09465599,  0.23717558,\n",
       "         0.18798423,  0.01224512,  0.0119217 ,  0.08053267,  0.06946623,\n",
       "         0.13331968,  0.14122361,  0.01789117,  0.01563036,  0.0739705 ,\n",
       "         0.0708102 ,  0.14038062,  0.20599586,  0.01974386,  0.03452599,\n",
       "         0.10514343,  0.0911938 ,  0.12678051,  0.13708425,  0.01563019,\n",
       "         0.01198983,  0.06394136,  0.10397202,  0.21949351,  0.19107956,\n",
       "         0.02501565,  0.02601773,  0.10160744,  0.11092007,  0.14520305,\n",
       "         0.12484723,  0.01837844,  0.01293927,  0.07812589,  0.08303255,\n",
       "         0.1474914 ,  0.1436705 ,  0.01563102,  0.01171964,  0.07031322,\n",
       "         0.06641185,  0.13706285,  0.14484471,  0.01171917,  0.0177626 ,\n",
       "         0.06816643,  0.06418425,  0.13677329,  0.12662679,  0.01171428,\n",
       "         0.01562512,  0.06401849,  0.062437  ,  0.12500107,  0.12849766,\n",
       "         0.01562524,  0.01953095,  0.08728427,  0.08558077,  0.15552694,\n",
       "         0.16406351,  0.01953626,  0.01562506,  0.07869285,  0.07812053,\n",
       "         0.15974438,  0.14559704,  0.01171398,  0.01562518,  0.0703131 ,\n",
       "         0.07062668,  0.13060963,  0.13858348,  0.01171899,  0.01562506,\n",
       "         0.06677955,  0.06641716,  0.13281405,  0.13494319,  0.01562548,\n",
       "         0.01562554,  0.06746644,  0.07031292,  0.13645446,  0.14476609,\n",
       "         0.01562512,  0.01562542,  0.07137346,  0.07285053,  0.13312304,\n",
       "         0.1328187 ,  0.01171923,  0.01562542,  0.06294852,  0.06956673,\n",
       "         0.1236732 ,  0.12768948,  0.00781274,  0.01562536,  0.06281352,\n",
       "         0.06641161,  0.12892115,  0.12507862,  0.01562566,  0.01952672,\n",
       "         0.07031798,  0.07753515,  0.1586802 ,  0.15339744,  0.01563084,\n",
       "         0.01562488,  0.07440269,  0.07812577,  0.13678735,  0.14029706,\n",
       "         0.01172423,  0.01632571,  0.07268351,  0.06944168,  0.14062637,\n",
       "         0.12890726,  0.01562613,  0.01522058,  0.06584769,  0.07812595,\n",
       "         0.15500593,  0.1328066 ,  0.01952636,  0.01953667,  0.08233225,\n",
       "         0.08442277,  0.1690774 ,  0.16902274,  0.01562554,  0.01562494,\n",
       "         0.07421911,  0.07844204,  0.15107185,  0.15715033,  0.01171893,\n",
       "         0.01562536,  0.08654869,  0.07031804,  0.17320889,  0.15061271,\n",
       "         0.02025974,  0.01248908,  0.07812566,  0.06556267,  0.12738371,\n",
       "         0.14292181]),\n",
       " 'mean_score_time': array([ 0.00175101,  0.00390625,  0.00740361,  0.0100739 ,  0.0155465 ,\n",
       "         0.01031518,  0.00175089,  0.00050032,  0.00638026,  0.01032305,\n",
       "         0.0010516 ,  0.01116705,  0.00050038,  0.00564778,  0.00515705,\n",
       "         0.00591254,  0.01031452,  0.00843263,  0.        ,  0.00567085,\n",
       "         0.00690389,  0.00745308,  0.00401926,  0.01042014,  0.00199926,\n",
       "         0.00440162,  0.00350243,  0.00324821,  0.01422089,  0.00390619,\n",
       "         0.        ,  0.        ,  0.00490701,  0.00391132,  0.01132023,\n",
       "         0.01011902,  0.        ,  0.        ,  0.00750422,  0.0066579 ,\n",
       "         0.01055962,  0.01177299,  0.00390589,  0.00049627,  0.        ,\n",
       "         0.00540721,  0.0144704 ,  0.00781274,  0.00390607,  0.00491202,\n",
       "         0.00450784,  0.00750446,  0.01174933,  0.01417923,  0.00050008,\n",
       "         0.00099558,  0.00391066,  0.00175166,  0.01516938,  0.01416558,\n",
       "         0.00300318,  0.00450057,  0.00565916,  0.00375396,  0.02376735,\n",
       "         0.00975597,  0.00544947,  0.00075054,  0.00454104,  0.00516224,\n",
       "         0.01256531,  0.00782275,  0.00075036,  0.00390637,  0.00540632,\n",
       "         0.00781322,  0.01107013,  0.01268315,  0.00100261,  0.00325215,\n",
       "         0.01164848,  0.01181954,  0.00781739,  0.01562512,  0.00396305,\n",
       "         0.        ,  0.        ,  0.00675052,  0.01516032,  0.01842391,\n",
       "         0.00250214,  0.00325155,  0.00475121,  0.01216435,  0.01376969,\n",
       "         0.00640464,  0.00125587,  0.00440675,  0.        ,  0.0025208 ,\n",
       "         0.01031005,  0.00390649,  0.        ,  0.00391108,  0.00390619,\n",
       "         0.0078125 ,  0.00781268,  0.00781304,  0.00390595,  0.00050515,\n",
       "         0.00150102,  0.00150108,  0.00492573,  0.01249105,  0.00390619,\n",
       "         0.        ,  0.00515729,  0.00390637,  0.01562154,  0.01030976,\n",
       "         0.00390649,  0.        ,  0.00931364,  0.00150114,  0.01171887,\n",
       "         0.01171869,  0.        ,  0.        ,  0.00390643,  0.00781763,\n",
       "         0.00640303,  0.01171851,  0.00390637,  0.        ,  0.00781268,\n",
       "         0.00390649,  0.01563096,  0.00781339,  0.00390613,  0.        ,\n",
       "         0.0122394 ,  0.00780797,  0.0125106 ,  0.00781286,  0.00390619,\n",
       "         0.        ,  0.01171875,  0.00390667,  0.01128721,  0.01031446,\n",
       "         0.        ,  0.        ,  0.        ,  0.00935537,  0.00781268,\n",
       "         0.0078131 ,  0.        ,  0.        ,  0.00782216,  0.0049482 ,\n",
       "         0.01171941,  0.00781286,  0.00390637,  0.        ,  0.00390631,\n",
       "         0.00390619,  0.00390142,  0.0078128 ,  0.        ,  0.        ,\n",
       "         0.01171911,  0.00390643,  0.01056457,  0.00780743,  0.00390595,\n",
       "         0.        ,  0.00390643,  0.01172316,  0.00781238,  0.00781769,\n",
       "         0.00390625,  0.00050038,  0.0051623 ,  0.00781274,  0.01250118,\n",
       "         0.01171398,  0.        ,  0.00050044,  0.00390631,  0.00390691,\n",
       "         0.        ,  0.00781697,  0.        ,  0.        ,  0.00782251,\n",
       "         0.01171941,  0.01171947,  0.00781757,  0.00390661,  0.0039112 ,\n",
       "         0.00781745,  0.00390619,  0.        ,  0.00594336,  0.00390643,\n",
       "         0.00391114,  0.00768471,  0.00781274,  0.01398146,  0.01571709,\n",
       "         0.00175422,  0.00390631,  0.00781262,  0.        ,  0.01171881,\n",
       "         0.00177842]),\n",
       " 'mean_test_score': array([ 0.79236813,  0.77104377,  0.78900112,  0.79685746,  0.78675645,\n",
       "         0.78451178,  0.78451178,  0.7620651 ,  0.78002245,  0.77777778,\n",
       "         0.78226712,  0.77890011,  0.77777778,  0.77441077,  0.76992144,\n",
       "         0.76767677,  0.77104377,  0.76992144,  0.78114478,  0.77104377,\n",
       "         0.77216611,  0.77104377,  0.77104377,  0.76655443,  0.78900112,\n",
       "         0.79124579,  0.79349046,  0.79573513,  0.79124579,  0.79012346,\n",
       "         0.76655443,  0.77328844,  0.78338945,  0.77553311,  0.78787879,\n",
       "         0.78338945,  0.77553311,  0.77553311,  0.77553311,  0.78114478,\n",
       "         0.78002245,  0.78114478,  0.7687991 ,  0.78451178,  0.77441077,\n",
       "         0.78563412,  0.78900112,  0.77328844,  0.77665544,  0.77665544,\n",
       "         0.77777778,  0.77665544,  0.77777778,  0.77665544,  0.77665544,\n",
       "         0.77665544,  0.77665544,  0.77665544,  0.77665544,  0.77665544,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.80022447,  0.8013468 ,  0.81818182,\n",
       "         0.81705948,  0.82042649,  0.81818182,  0.79573513,  0.77777778,\n",
       "         0.79012346,  0.79685746,  0.78226712,  0.79349046,  0.76992144,\n",
       "         0.77328844,  0.7687991 ,  0.77665544,  0.77104377,  0.7687991 ,\n",
       "         0.77104377,  0.72727273,  0.77216611,  0.77104377,  0.77665544,\n",
       "         0.7687991 ,  0.81818182,  0.81818182,  0.82267116,  0.81930415,\n",
       "         0.82042649,  0.82042649,  0.78451178,  0.79573513,  0.78226712,\n",
       "         0.79012346,  0.78563412,  0.79124579,  0.76992144,  0.77777778,\n",
       "         0.77890011,  0.78226712,  0.77777778,  0.78675645,  0.77553311,\n",
       "         0.78114478,  0.78114478,  0.77777778,  0.78451178,  0.78114478,\n",
       "         0.81257015,  0.80695847,  0.81705948,  0.81593715,  0.81369248,\n",
       "         0.82154882,  0.80022447,  0.79910213,  0.79685746,  0.79910213,\n",
       "         0.79910213,  0.7979798 ,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.81369248,\n",
       "         0.81257015,  0.82603816,  0.81930415,  0.81593715,  0.82154882,\n",
       "         0.78114478,  0.79236813,  0.79124579,  0.79910213,  0.79685746,\n",
       "         0.78675645,  0.77890011,  0.76655443,  0.7654321 ,  0.77665544,\n",
       "         0.76655443,  0.7687991 ,  0.77665544,  0.77216611,  0.7654321 ,\n",
       "         0.76655443,  0.76430976,  0.7687991 ,  0.80808081,  0.80583614,\n",
       "         0.81481481,  0.81481481,  0.81818182,  0.82042649,  0.79910213,\n",
       "         0.78114478,  0.79461279,  0.79012346,  0.78675645,  0.79461279,\n",
       "         0.77553311,  0.78002245,  0.78451178,  0.77553311,  0.77890011,\n",
       "         0.78002245,  0.7687991 ,  0.77553311,  0.77777778,  0.78114478,\n",
       "         0.78451178,  0.77216611,  0.81369248,  0.81481481,  0.82042649,\n",
       "         0.81369248,  0.82042649,  0.81593715,  0.79685746,  0.79349046,\n",
       "         0.79910213,  0.7979798 ,  0.79685746,  0.79685746,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645,  0.78675645,  0.78675645,  0.78675645,  0.78675645,\n",
       "         0.78675645]),\n",
       " 'mean_train_score': array([ 0.80920334,  0.79461816,  0.80471344,  0.80433975,  0.79685864,\n",
       "         0.80209256,  0.79460641,  0.78413632,  0.79125158,  0.78899936,\n",
       "         0.7931178 ,  0.79386407,  0.78713369,  0.78450722,  0.77627984,\n",
       "         0.7770317 ,  0.78301581,  0.7770289 ,  0.78376039,  0.77739924,\n",
       "         0.78077477,  0.7744125 ,  0.77403769,  0.77777852,  0.79611069,\n",
       "         0.80283379,  0.80172223,  0.80508937,  0.79536331,  0.79386183,\n",
       "         0.78488874,  0.79012714,  0.78788164,  0.78750403,  0.78974842,\n",
       "         0.79648606,  0.77890128,  0.7785287 ,  0.78189585,  0.78451337,\n",
       "         0.78563781,  0.78488874,  0.7819048 ,  0.78301581,  0.78077365,\n",
       "         0.78862734,  0.78900047,  0.78077365,  0.79423608,  0.79311332,\n",
       "         0.79648159,  0.79386127,  0.79386183,  0.79461089,  0.79012379,\n",
       "         0.79012379,  0.79012379,  0.79012379,  0.79012379,  0.79012379,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.84175147,  0.83314481,  0.84175036,\n",
       "         0.84324792,  0.84062872,  0.84287367,  0.80808115,  0.79723401,\n",
       "         0.80920502,  0.81368933,  0.80621381,  0.80920278,  0.77516212,\n",
       "         0.77029573,  0.77740092,  0.78264379,  0.77403713,  0.77553525,\n",
       "         0.78002347,  0.74073322,  0.77216923,  0.78002403,  0.7781511 ,\n",
       "         0.77777852,  0.84287087,  0.83688565,  0.85259638,  0.8481076 ,\n",
       "         0.84362273,  0.8451147 ,  0.8069556 ,  0.80733264,  0.81294418,\n",
       "         0.80695727,  0.80845372,  0.80882909,  0.77891303,  0.78601373,\n",
       "         0.78226954,  0.78713481,  0.78339062,  0.79086893,  0.77553581,\n",
       "         0.78339453,  0.7807703 ,  0.77815054,  0.78563557,  0.78600814,\n",
       "         0.84698652,  0.84661227,  0.85222101,  0.85820847,  0.85671426,\n",
       "         0.8578359 ,  0.80695951,  0.8058362 ,  0.80696119,  0.80546418,\n",
       "         0.80508993,  0.80770801,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.84062872,\n",
       "         0.83202485,  0.84848297,  0.84362049,  0.8462397 ,  0.84886057,\n",
       "         0.79498011,  0.79835285,  0.81294194,  0.81518577,  0.81368765,\n",
       "         0.80957927,  0.78339341,  0.77553301,  0.77516156,  0.78077198,\n",
       "         0.78189361,  0.77777796,  0.77627928,  0.77816117,  0.77329142,\n",
       "         0.77964866,  0.77890184,  0.77740427,  0.84848297,  0.846991  ,\n",
       "         0.85147418,  0.84997941,  0.84773446,  0.84848241,  0.8058362 ,\n",
       "         0.80433751,  0.81144717,  0.80957647,  0.80583452,  0.81331731,\n",
       "         0.78713425,  0.78563725,  0.79087117,  0.78114679,  0.78451449,\n",
       "         0.78526355,  0.77703226,  0.78676056,  0.77815333,  0.78676112,\n",
       "         0.78376431,  0.77703226,  0.85297119,  0.85371745,  0.85671426,\n",
       "         0.85596688,  0.85858608,  0.85858496,  0.80434143,  0.80658806,\n",
       "         0.80882909,  0.80583788,  0.80546362,  0.80471624,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832,  0.78675832,  0.78675832,  0.78675832,  0.78675832,\n",
       "         0.78675832]),\n",
       " 'param_max_depth': masked_array(data = [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
       "  2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6\n",
       "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
       "  6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
       "  10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_max_features': masked_array(data = [3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 3 3\n",
       "  3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 3 3 3 3\n",
       "  3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
       "  5 5 5 5 5 5 5 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_min_samples_leaf': masked_array(data = [10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100 100 100\n",
       "  100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100 100\n",
       "  100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100 100\n",
       "  100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100 100\n",
       "  100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70 100\n",
       "  100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70 70\n",
       "  100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70 70\n",
       "  70 100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70 70\n",
       "  70 70 100 100 100 100 100 100 10 10 10 10 10 10 30 30 30 30 30 30 70 70 70\n",
       "  70 70 70 100 100 100 100 100 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_n_estimators': masked_array(data = [10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50\n",
       "  100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10\n",
       "  50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100\n",
       "  10 10 50 50 100 100 10 10 50 50 100 100 10 10 50 50 100 100],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_warm_start': masked_array(data = [0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
       "  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
       "  0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
       "  1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 2,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 3,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 30,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 70,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 10,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 50,\n",
       "   'warm_start': 1},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 0},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 100,\n",
       "   'n_estimators': 100,\n",
       "   'warm_start': 1}),\n",
       " 'rank_test_score': array([ 61, 187,  71,  46,  75, 117, 117, 215, 139, 147, 126, 143, 147,\n",
       "        178, 195, 206, 187, 195, 130, 187, 183, 187, 187, 207,  71,  63,\n",
       "         58,  53,  63,  67, 207, 180, 124, 170,  74, 124, 170, 170, 170,\n",
       "        130, 139, 130, 199, 117, 178, 115,  71, 180, 156, 156, 147, 156,\n",
       "        147, 156, 156, 156, 156, 156, 156, 156,  75,  75,  75,  75,  75,\n",
       "         75,  75,  75,  75,  75,  75,  75,  36,  35,  13,  18,   5,  13,\n",
       "         53, 147,  67,  46, 126,  58, 195, 180, 199, 156, 187, 199, 187,\n",
       "        216, 183, 187, 156, 199,  13,  13,   2,  11,   5,   5, 117,  53,\n",
       "        126,  67, 115,  63, 195, 147, 143, 126, 147,  75, 170, 130, 130,\n",
       "        147, 117, 130,  30,  33,  18,  20,  26,   3,  36,  38,  46,  38,\n",
       "         38,  44,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,  75,\n",
       "         75,  26,  30,   1,  11,  20,   3, 130,  61,  63,  38,  46,  75,\n",
       "        143, 207, 212, 156, 207, 199, 156, 183, 212, 207, 214, 199,  32,\n",
       "         34,  23,  23,  13,   5,  38, 130,  56,  67,  75,  56, 170, 139,\n",
       "        117, 170, 143, 139, 199, 170, 147, 130, 117, 183,  26,  23,   5,\n",
       "         26,   5,  20,  46,  58,  38,  44,  46,  46,  75,  75,  75,  75,\n",
       "         75,  75,  75,  75,  75,  75,  75,  75]),\n",
       " 'split0_test_score': array([ 0.79820628,  0.78026906,  0.80269058,  0.8161435 ,  0.80269058,\n",
       "         0.78026906,  0.8161435 ,  0.76681614,  0.77578475,  0.77130045,\n",
       "         0.79372197,  0.77130045,  0.79372197,  0.77130045,  0.76233184,\n",
       "         0.77130045,  0.76681614,  0.77130045,  0.77130045,  0.76233184,\n",
       "         0.77130045,  0.77130045,  0.76681614,  0.77130045,  0.78923767,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.76681614,  0.78026906,  0.79372197,  0.77130045,  0.78923767,\n",
       "         0.78475336,  0.77130045,  0.77130045,  0.77130045,  0.78923767,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.81165919,  0.83856502,  0.8161435 ,\n",
       "         0.83856502,  0.83856502,  0.82959641,  0.83408072,  0.80717489,\n",
       "         0.79372197,  0.79372197,  0.78026906,  0.79372197,  0.77130045,\n",
       "         0.8161435 ,  0.77130045,  0.78475336,  0.77130045,  0.77130045,\n",
       "         0.77130045,  0.76233184,  0.76681614,  0.77130045,  0.80269058,\n",
       "         0.76681614,  0.83856502,  0.83408072,  0.83408072,  0.83408072,\n",
       "         0.83856502,  0.82959641,  0.77578475,  0.81165919,  0.79820628,\n",
       "         0.78475336,  0.78026906,  0.78475336,  0.78026906,  0.79372197,\n",
       "         0.80269058,  0.78026906,  0.78026906,  0.78026906,  0.77578475,\n",
       "         0.78026906,  0.77130045,  0.77578475,  0.78026906,  0.78026906,\n",
       "         0.83408072,  0.82511211,  0.82959641,  0.82959641,  0.82511211,\n",
       "         0.82511211,  0.81165919,  0.8161435 ,  0.8161435 ,  0.8161435 ,\n",
       "         0.8161435 ,  0.8161435 ,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.82511211,\n",
       "         0.81165919,  0.83408072,  0.82511211,  0.82959641,  0.83408072,\n",
       "         0.77578475,  0.80269058,  0.78923767,  0.78923767,  0.79372197,\n",
       "         0.79372197,  0.78026906,  0.75784753,  0.77578475,  0.77130045,\n",
       "         0.77130045,  0.76681614,  0.77130045,  0.78026906,  0.77130045,\n",
       "         0.77130045,  0.77130045,  0.77130045,  0.84304933,  0.84304933,\n",
       "         0.8206278 ,  0.83408072,  0.82511211,  0.83408072,  0.78026906,\n",
       "         0.77578475,  0.78026906,  0.78923767,  0.78026906,  0.80717489,\n",
       "         0.78026906,  0.78026906,  0.78923767,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.79372197,  0.78026906,  0.77578475,  0.78026906,\n",
       "         0.77130045,  0.78026906,  0.83408072,  0.83408072,  0.83856502,\n",
       "         0.8161435 ,  0.82959641,  0.82511211,  0.8161435 ,  0.82511211,\n",
       "         0.8161435 ,  0.8161435 ,  0.8161435 ,  0.8161435 ,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906]),\n",
       " 'split0_train_score': array([ 0.81137725,  0.78892216,  0.80688623,  0.80389222,  0.79491018,\n",
       "         0.78892216,  0.79640719,  0.76946108,  0.77694611,  0.77694611,\n",
       "         0.79341317,  0.78143713,  0.79491018,  0.77694611,  0.7739521 ,\n",
       "         0.77844311,  0.77694611,  0.77844311,  0.76796407,  0.76946108,\n",
       "         0.77844311,  0.77844311,  0.77694611,  0.77694611,  0.80389222,\n",
       "         0.79191617,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.77994012,  0.78892216,  0.79341317,  0.77694611,  0.78892216,\n",
       "         0.78892216,  0.77694611,  0.77694611,  0.77694611,  0.79041916,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.79191617,\n",
       "         0.79191617,  0.78892216,  0.79191617,  0.79191617,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.8502994 ,  0.82784431,  0.8488024 ,\n",
       "         0.84281437,  0.84730539,  0.84730539,  0.81137725,  0.80538922,\n",
       "         0.80239521,  0.79341317,  0.79041916,  0.79341317,  0.77694611,\n",
       "         0.76946108,  0.77844311,  0.79341317,  0.7739521 ,  0.77694611,\n",
       "         0.76796407,  0.77095808,  0.77844311,  0.77245509,  0.78293413,\n",
       "         0.77694611,  0.84580838,  0.83083832,  0.84730539,  0.8502994 ,\n",
       "         0.84580838,  0.84281437,  0.79041916,  0.79640719,  0.81137725,\n",
       "         0.78892216,  0.79491018,  0.79790419,  0.78892216,  0.79640719,\n",
       "         0.78443114,  0.78892216,  0.78892216,  0.78892216,  0.76946108,\n",
       "         0.78892216,  0.77694611,  0.77095808,  0.78892216,  0.78892216,\n",
       "         0.84431138,  0.84131737,  0.84281437,  0.8502994 ,  0.85628743,\n",
       "         0.85479042,  0.7994012 ,  0.79640719,  0.80239521,  0.8008982 ,\n",
       "         0.79790419,  0.79790419,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.82934132,\n",
       "         0.82634731,  0.85179641,  0.85778443,  0.83982036,  0.8502994 ,\n",
       "         0.76796407,  0.78892216,  0.8008982 ,  0.79640719,  0.79191617,\n",
       "         0.80389222,  0.78892216,  0.77095808,  0.77844311,  0.7739521 ,\n",
       "         0.77844311,  0.77994012,  0.77694611,  0.78892216,  0.77694611,\n",
       "         0.77844311,  0.77844311,  0.77844311,  0.86077844,  0.84730539,\n",
       "         0.84730539,  0.85179641,  0.84580838,  0.84580838,  0.79341317,\n",
       "         0.79041916,  0.79491018,  0.80389222,  0.79041916,  0.80688623,\n",
       "         0.78892216,  0.78892216,  0.79640719,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78443114,  0.78892216,  0.76946108,  0.78892216,\n",
       "         0.77694611,  0.78892216,  0.84431138,  0.85179641,  0.85628743,\n",
       "         0.85628743,  0.85628743,  0.86227545,  0.79790419,  0.80538922,\n",
       "         0.7994012 ,  0.79790419,  0.79640719,  0.79640719,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216]),\n",
       " 'split1_test_score': array([ 0.77578475,  0.79372197,  0.78026906,  0.79820628,  0.79372197,\n",
       "         0.79372197,  0.78475336,  0.77578475,  0.78475336,  0.76681614,\n",
       "         0.78475336,  0.80717489,  0.78026906,  0.77578475,  0.77578475,\n",
       "         0.77578475,  0.78026906,  0.77130045,  0.78475336,  0.77578475,\n",
       "         0.77578475,  0.76681614,  0.77130045,  0.75784753,  0.78026906,\n",
       "         0.79372197,  0.81165919,  0.81165919,  0.79372197,  0.79372197,\n",
       "         0.77130045,  0.79372197,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.80269058,  0.78026906,  0.78923767,\n",
       "         0.78923767,  0.78026906,  0.78026906,  0.78026906,  0.76233184,\n",
       "         0.78026906,  0.78026906,  0.76233184,  0.78475336,  0.78923767,\n",
       "         0.78475336,  0.78923767,  0.78923767,  0.78475336,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.79372197,  0.81165919,  0.84753363,\n",
       "         0.83856502,  0.83856502,  0.83856502,  0.79820628,  0.74439462,\n",
       "         0.82511211,  0.80717489,  0.79820628,  0.80717489,  0.76233184,\n",
       "         0.74439462,  0.76233184,  0.78475336,  0.77130045,  0.76681614,\n",
       "         0.76233184,  0.78026906,  0.78026906,  0.77130045,  0.76681614,\n",
       "         0.77578475,  0.81165919,  0.8206278 ,  0.8206278 ,  0.82511211,\n",
       "         0.82959641,  0.82959641,  0.78923767,  0.79820628,  0.77578475,\n",
       "         0.80269058,  0.80269058,  0.80269058,  0.78026906,  0.77578475,\n",
       "         0.78026906,  0.78923767,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78475336,  0.76681614,  0.77130045,  0.77130045,  0.78923767,\n",
       "         0.8206278 ,  0.8161435 ,  0.82511211,  0.8161435 ,  0.82959641,\n",
       "         0.82959641,  0.79820628,  0.79820628,  0.79820628,  0.80269058,\n",
       "         0.79820628,  0.79820628,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.80717489,\n",
       "         0.82511211,  0.83408072,  0.85201794,  0.82959641,  0.84304933,\n",
       "         0.79820628,  0.80269058,  0.81165919,  0.8206278 ,  0.8161435 ,\n",
       "         0.80717489,  0.77130045,  0.78923767,  0.76233184,  0.78923767,\n",
       "         0.75784753,  0.77130045,  0.75784753,  0.78026906,  0.75784753,\n",
       "         0.76681614,  0.75784753,  0.77130045,  0.80717489,  0.80269058,\n",
       "         0.82511211,  0.82511211,  0.82511211,  0.8206278 ,  0.80717489,\n",
       "         0.78475336,  0.80717489,  0.80269058,  0.79820628,  0.8161435 ,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.76233184,  0.81165919,  0.82959641,  0.8206278 ,\n",
       "         0.83856502,  0.83408072,  0.83408072,  0.79820628,  0.80269058,\n",
       "         0.79820628,  0.79820628,  0.79820628,  0.79820628,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906,  0.78026906,  0.78026906,  0.78026906,  0.78026906,\n",
       "         0.78026906]),\n",
       " 'split1_train_score': array([ 0.79491018,  0.79491018,  0.78443114,  0.80389222,  0.78892216,\n",
       "         0.8008982 ,  0.78742515,  0.78742515,  0.78742515,  0.7739521 ,\n",
       "         0.78443114,  0.79491018,  0.78892216,  0.77095808,  0.7754491 ,\n",
       "         0.7754491 ,  0.7754491 ,  0.7739521 ,  0.78742515,  0.7754491 ,\n",
       "         0.7739521 ,  0.78293413,  0.77994012,  0.77844311,  0.78892216,\n",
       "         0.77844311,  0.7994012 ,  0.81287425,  0.80239521,  0.78742515,\n",
       "         0.78892216,  0.78443114,  0.78443114,  0.78742515,  0.78892216,\n",
       "         0.78892216,  0.7754491 ,  0.79191617,  0.78892216,  0.79191617,\n",
       "         0.7994012 ,  0.7754491 ,  0.78892216,  0.78892216,  0.7739521 ,\n",
       "         0.78892216,  0.78892216,  0.7739521 ,  0.78742515,  0.78742515,\n",
       "         0.79041916,  0.78892216,  0.78742515,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.82934132,  0.83532934,  0.83383234,\n",
       "         0.83233533,  0.83383234,  0.83682635,  0.81287425,  0.78592814,\n",
       "         0.80988024,  0.81287425,  0.80988024,  0.81287425,  0.7739521 ,\n",
       "         0.74850299,  0.7739521 ,  0.78742515,  0.77245509,  0.7739521 ,\n",
       "         0.7739521 ,  0.7739521 ,  0.7754491 ,  0.77844311,  0.76946108,\n",
       "         0.77095808,  0.82634731,  0.83083832,  0.84131737,  0.82934132,\n",
       "         0.83532934,  0.83233533,  0.80538922,  0.8008982 ,  0.80838323,\n",
       "         0.80688623,  0.80688623,  0.80688623,  0.78892216,  0.78293413,\n",
       "         0.78892216,  0.79640719,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78742515,  0.77694611,  0.77694611,  0.7739521 ,  0.79491018,\n",
       "         0.84281437,  0.84580838,  0.83982036,  0.84431138,  0.84431138,\n",
       "         0.84580838,  0.80838323,  0.80538922,  0.80838323,  0.80838323,\n",
       "         0.80838323,  0.80838323,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.82934132,\n",
       "         0.82185629,  0.83233533,  0.83083832,  0.83982036,  0.84281437,\n",
       "         0.79191617,  0.8008982 ,  0.80988024,  0.81137725,  0.80988024,\n",
       "         0.80838323,  0.78443114,  0.78293413,  0.77844311,  0.77844311,\n",
       "         0.7754491 ,  0.77095808,  0.77095808,  0.7754491 ,  0.7739521 ,\n",
       "         0.7739521 ,  0.77844311,  0.77694611,  0.83233533,  0.83832335,\n",
       "         0.84131737,  0.83383234,  0.82934132,  0.83083832,  0.80688623,\n",
       "         0.8008982 ,  0.80838323,  0.80988024,  0.80538922,  0.80988024,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.7739521 ,  0.84281437,  0.84131737,  0.85179641,\n",
       "         0.84730539,  0.85479042,  0.84730539,  0.80838323,  0.80838323,\n",
       "         0.80838323,  0.80838323,  0.80838323,  0.80838323,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216,  0.78892216,  0.78892216,  0.78892216,  0.78892216,\n",
       "         0.78892216]),\n",
       " 'split2_test_score': array([ 0.78923767,  0.76233184,  0.78923767,  0.77130045,  0.77578475,\n",
       "         0.78923767,  0.74439462,  0.74887892,  0.78923767,  0.79372197,\n",
       "         0.78026906,  0.77130045,  0.76681614,  0.78026906,  0.76681614,\n",
       "         0.75784753,  0.76681614,  0.76681614,  0.78475336,  0.76681614,\n",
       "         0.77578475,  0.77578475,  0.77578475,  0.77130045,  0.78923767,\n",
       "         0.78026906,  0.78475336,  0.78923767,  0.79372197,  0.78923767,\n",
       "         0.75784753,  0.75336323,  0.78026906,  0.78026906,  0.78475336,\n",
       "         0.79372197,  0.78475336,  0.75784753,  0.78475336,  0.77130045,\n",
       "         0.77578475,  0.78475336,  0.77130045,  0.77578475,  0.78475336,\n",
       "         0.78923767,  0.78475336,  0.78475336,  0.77130045,  0.76681614,\n",
       "         0.77578475,  0.76681614,  0.77130045,  0.77130045,  0.76681614,\n",
       "         0.76681614,  0.76681614,  0.76681614,  0.76681614,  0.76681614,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.75784753,  0.80269058,\n",
       "         0.78026906,  0.78923767,  0.78923767,  0.76233184,  0.77578475,\n",
       "         0.77130045,  0.78026906,  0.77578475,  0.78026906,  0.77130045,\n",
       "         0.76681614,  0.77130045,  0.77130045,  0.76233184,  0.76681614,\n",
       "         0.78475336,  0.60538117,  0.77130045,  0.76681614,  0.77130045,\n",
       "         0.76681614,  0.80269058,  0.79820628,  0.8161435 ,  0.79372197,\n",
       "         0.79820628,  0.80717489,  0.77578475,  0.76681614,  0.76681614,\n",
       "         0.76681614,  0.76681614,  0.78026906,  0.76681614,  0.76681614,\n",
       "         0.75784753,  0.78475336,  0.77578475,  0.78475336,  0.77130045,\n",
       "         0.78475336,  0.78475336,  0.76233184,  0.78475336,  0.76233184,\n",
       "         0.78475336,  0.79820628,  0.80717489,  0.80717489,  0.80269058,\n",
       "         0.8206278 ,  0.77578475,  0.77578475,  0.77578475,  0.77130045,\n",
       "         0.77578475,  0.77578475,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.80717489,\n",
       "         0.79372197,  0.81165919,  0.78923767,  0.78475336,  0.79372197,\n",
       "         0.75336323,  0.78026906,  0.77130045,  0.78475336,  0.77130045,\n",
       "         0.77578475,  0.78923767,  0.75336323,  0.75784753,  0.77130045,\n",
       "         0.76681614,  0.76681614,  0.77578475,  0.78475336,  0.77130045,\n",
       "         0.75784753,  0.76233184,  0.76681614,  0.76233184,  0.77130045,\n",
       "         0.79372197,  0.80269058,  0.80717489,  0.8161435 ,  0.80269058,\n",
       "         0.77130045,  0.77578475,  0.77578475,  0.77578475,  0.77578475,\n",
       "         0.76681614,  0.78475336,  0.77578475,  0.76681614,  0.78026906,\n",
       "         0.78475336,  0.74439462,  0.76681614,  0.77578475,  0.78923767,\n",
       "         0.78475336,  0.77130045,  0.80717489,  0.79372197,  0.8161435 ,\n",
       "         0.81165919,  0.8161435 ,  0.80717489,  0.77130045,  0.77578475,\n",
       "         0.77578475,  0.77578475,  0.77130045,  0.77130045,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336,  0.78475336,  0.78475336,  0.78475336,  0.78475336,\n",
       "         0.78475336]),\n",
       " 'split2_train_score': array([ 0.82185629,  0.81437126,  0.82185629,  0.80538922,  0.80988024,\n",
       "         0.80988024,  0.78293413,  0.79191617,  0.8248503 ,  0.81137725,\n",
       "         0.80538922,  0.80389222,  0.78592814,  0.79341317,  0.7754491 ,\n",
       "         0.78293413,  0.79790419,  0.77694611,  0.78742515,  0.7754491 ,\n",
       "         0.8008982 ,  0.76646707,  0.76796407,  0.77994012,  0.7994012 ,\n",
       "         0.81287425,  0.82185629,  0.81886228,  0.80239521,  0.7994012 ,\n",
       "         0.79341317,  0.80688623,  0.79341317,  0.79640719,  0.78892216,\n",
       "         0.81886228,  0.78742515,  0.7739521 ,  0.78742515,  0.7754491 ,\n",
       "         0.77844311,  0.79790419,  0.7994012 ,  0.77245509,  0.78742515,\n",
       "         0.78892216,  0.78742515,  0.78742515,  0.7994012 ,  0.79191617,\n",
       "         0.80239521,  0.79491018,  0.79491018,  0.79790419,  0.79341317,\n",
       "         0.79341317,  0.79341317,  0.79341317,  0.79341317,  0.79341317,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.84730539,  0.83233533,  0.84131737,\n",
       "         0.85628743,  0.84131737,  0.84580838,  0.8008982 ,  0.80688623,\n",
       "         0.82035928,  0.82634731,  0.82784431,  0.82035928,  0.78293413,\n",
       "         0.79341317,  0.77245509,  0.7739521 ,  0.77694611,  0.78143713,\n",
       "         0.8008982 ,  0.65718563,  0.77095808,  0.79341317,  0.77994012,\n",
       "         0.78742515,  0.8502994 ,  0.84431138,  0.85928144,  0.85628743,\n",
       "         0.85329341,  0.85179641,  0.81736527,  0.8248503 ,  0.81886228,\n",
       "         0.82185629,  0.82035928,  0.82185629,  0.79341317,  0.79341317,\n",
       "         0.77994012,  0.78742515,  0.7754491 ,  0.78742515,  0.7754491 ,\n",
       "         0.78742515,  0.78742515,  0.78293413,  0.79790419,  0.7739521 ,\n",
       "         0.8488024 ,  0.84730539,  0.86077844,  0.87125749,  0.86676647,\n",
       "         0.86826347,  0.81586826,  0.81586826,  0.81736527,  0.81287425,\n",
       "         0.81437126,  0.82035928,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.86377246,\n",
       "         0.8502994 ,  0.85628743,  0.83982036,  0.85778443,  0.85778443,\n",
       "         0.80688623,  0.80239521,  0.82185629,  0.82934132,  0.82634731,\n",
       "         0.82185629,  0.78742515,  0.77245509,  0.7754491 ,  0.79341317,\n",
       "         0.79341317,  0.78293413,  0.7754491 ,  0.79491018,  0.77694611,\n",
       "         0.78742515,  0.78443114,  0.77844311,  0.84730539,  0.86227545,\n",
       "         0.85628743,  0.85928144,  0.86227545,  0.86227545,  0.81736527,\n",
       "         0.81586826,  0.82934132,  0.81287425,  0.81736527,  0.82035928,\n",
       "         0.79341317,  0.78742515,  0.78592814,  0.77095808,  0.78293413,\n",
       "         0.78742515,  0.76497006,  0.79341317,  0.77994012,  0.79491018,\n",
       "         0.78742515,  0.7754491 ,  0.86377246,  0.85479042,  0.85928144,\n",
       "         0.86377246,  0.86526946,  0.86377246,  0.81137725,  0.81586826,\n",
       "         0.81886228,  0.81586826,  0.81586826,  0.81586826,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515,  0.78742515,  0.78742515,  0.78742515,  0.78742515,\n",
       "         0.78742515]),\n",
       " 'split3_test_score': array([ 0.80630631,  0.74774775,  0.78378378,  0.8018018 ,  0.77477477,\n",
       "         0.77477477,  0.79279279,  0.75675676,  0.77027027,  0.77927928,\n",
       "         0.77027027,  0.76576577,  0.77027027,  0.77027027,  0.77477477,\n",
       "         0.76576577,  0.77027027,  0.77027027,  0.78378378,  0.77927928,\n",
       "         0.76576577,  0.77027027,  0.77027027,  0.76576577,  0.7972973 ,\n",
       "         0.81081081,  0.7972973 ,  0.8018018 ,  0.7972973 ,  0.7972973 ,\n",
       "         0.77027027,  0.76576577,  0.77927928,  0.77027027,  0.7972973 ,\n",
       "         0.77477477,  0.76576577,  0.77027027,  0.76576577,  0.77477477,\n",
       "         0.77477477,  0.77927928,  0.74324324,  0.8018018 ,  0.77027027,\n",
       "         0.79279279,  0.81081081,  0.76576577,  0.77027027,  0.77027027,\n",
       "         0.77027027,  0.77027027,  0.77027027,  0.77027027,  0.77927928,\n",
       "         0.77927928,  0.77927928,  0.77927928,  0.77927928,  0.77927928,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.81081081,  0.7972973 ,  0.80630631,\n",
       "         0.81081081,  0.81531532,  0.81531532,  0.78828829,  0.78378378,\n",
       "         0.77027027,  0.80630631,  0.77477477,  0.79279279,  0.77477477,\n",
       "         0.76576577,  0.77027027,  0.76576577,  0.77927928,  0.77027027,\n",
       "         0.76576577,  0.76126126,  0.77027027,  0.77477477,  0.76576577,\n",
       "         0.76576577,  0.81981982,  0.81981982,  0.81981982,  0.82432432,\n",
       "         0.81531532,  0.81531532,  0.7972973 ,  0.80630631,  0.78828829,\n",
       "         0.80630631,  0.79279279,  0.7972973 ,  0.75225225,  0.77477477,\n",
       "         0.77477477,  0.77477477,  0.77477477,  0.8018018 ,  0.77477477,\n",
       "         0.77477477,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.79279279,\n",
       "         0.81081081,  0.78828829,  0.80630631,  0.81081081,  0.7972973 ,\n",
       "         0.81081081,  0.81531532,  0.80630631,  0.7972973 ,  0.80630631,\n",
       "         0.80630631,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.81531532,\n",
       "         0.81981982,  0.82432432,  0.81081081,  0.81981982,  0.81531532,\n",
       "         0.7972973 ,  0.78378378,  0.79279279,  0.8018018 ,  0.80630631,\n",
       "         0.77027027,  0.77477477,  0.76576577,  0.76576577,  0.77477477,\n",
       "         0.77027027,  0.77027027,  0.8018018 ,  0.74324324,  0.76126126,\n",
       "         0.77027027,  0.76576577,  0.76576577,  0.81981982,  0.80630631,\n",
       "         0.81981982,  0.7972973 ,  0.81531532,  0.81081081,  0.80630631,\n",
       "         0.79279279,  0.81531532,  0.79279279,  0.79279279,  0.77927928,\n",
       "         0.77477477,  0.77477477,  0.79279279,  0.77477477,  0.77477477,\n",
       "         0.77477477,  0.75675676,  0.77477477,  0.77927928,  0.77477477,\n",
       "         0.8018018 ,  0.77477477,  0.8018018 ,  0.8018018 ,  0.80630631,\n",
       "         0.78828829,  0.8018018 ,  0.7972973 ,  0.8018018 ,  0.77027027,\n",
       "         0.80630631,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,  0.8018018 ,\n",
       "         0.8018018 ]),\n",
       " 'split3_train_score': array([ 0.80866966,  0.78026906,  0.80568012,  0.80418535,  0.79372197,\n",
       "         0.80866966,  0.81165919,  0.7877429 ,  0.77578475,  0.79372197,\n",
       "         0.78923767,  0.79521674,  0.77877429,  0.79671151,  0.78026906,\n",
       "         0.77130045,  0.78176383,  0.77877429,  0.7922272 ,  0.78923767,\n",
       "         0.76980568,  0.76980568,  0.77130045,  0.77578475,  0.7922272 ,\n",
       "         0.82810164,  0.79820628,  0.80119581,  0.78923767,  0.80119581,\n",
       "         0.77727952,  0.78026906,  0.78026906,  0.78923767,  0.7922272 ,\n",
       "         0.78923767,  0.77578475,  0.77130045,  0.77428999,  0.78026906,\n",
       "         0.77578475,  0.77727952,  0.75037369,  0.78176383,  0.77279522,\n",
       "         0.7877429 ,  0.79073244,  0.77279522,  0.80119581,  0.80119581,\n",
       "         0.80119581,  0.80269058,  0.80119581,  0.79970105,  0.78923767,\n",
       "         0.78923767,  0.78923767,  0.78923767,  0.78923767,  0.78923767,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.84005979,  0.83707025,  0.84304933,\n",
       "         0.84155456,  0.84005979,  0.84155456,  0.80717489,  0.79073244,\n",
       "         0.80418535,  0.82212257,  0.79671151,  0.81016442,  0.76681614,\n",
       "         0.76980568,  0.78475336,  0.77578475,  0.77279522,  0.76980568,\n",
       "         0.77727952,  0.76083707,  0.76382661,  0.77578475,  0.78026906,\n",
       "         0.77578475,  0.8490284 ,  0.84155456,  0.86248132,  0.85650224,\n",
       "         0.84005979,  0.85351271,  0.81464873,  0.80717489,  0.81315396,\n",
       "         0.81016442,  0.81165919,  0.80866966,  0.74439462,  0.77130045,\n",
       "         0.77578475,  0.77578475,  0.78026906,  0.79820628,  0.76831091,\n",
       "         0.76980568,  0.78176383,  0.78176383,  0.78176383,  0.78624813,\n",
       "         0.85201794,  0.85201794,  0.86547085,  0.86696562,  0.85949178,\n",
       "         0.86248132,  0.80418535,  0.80568012,  0.79970105,  0.79970105,\n",
       "         0.79970105,  0.80418535,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.84005979,\n",
       "         0.82959641,  0.85351271,  0.84603886,  0.84753363,  0.8445441 ,\n",
       "         0.81315396,  0.80119581,  0.81913303,  0.82361734,  0.82660688,\n",
       "         0.80418535,  0.77279522,  0.77578475,  0.76831091,  0.77727952,\n",
       "         0.78026906,  0.77727952,  0.78176383,  0.75336323,  0.76532138,\n",
       "         0.77877429,  0.77428999,  0.77578475,  0.85351271,  0.84005979,\n",
       "         0.86098655,  0.85500747,  0.85351271,  0.85500747,  0.80568012,\n",
       "         0.81016442,  0.81315396,  0.81165919,  0.81016442,  0.8161435 ,\n",
       "         0.77727952,  0.77727952,  0.7922272 ,  0.77578475,  0.77727952,\n",
       "         0.77578475,  0.76980568,  0.77578475,  0.77428999,  0.77428999,\n",
       "         0.78176383,  0.76980568,  0.86098655,  0.86696562,  0.85949178,\n",
       "         0.85650224,  0.85799701,  0.86098655,  0.79970105,  0.79671151,\n",
       "         0.80866966,  0.80119581,  0.80119581,  0.79820628,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383,  0.78176383,  0.78176383,  0.78176383,  0.78176383,\n",
       "         0.78176383]),\n",
       " 'std_fit_time': array([  4.92173703e-03,   3.70577273e-03,   1.45311344e-02,\n",
       "          1.35814615e-02,   1.04463999e-02,   6.34555970e-03,\n",
       "          2.87723590e-03,   7.23338188e-03,   1.32102071e-02,\n",
       "          2.30585854e-02,   7.86836144e-03,   1.65890849e-02,\n",
       "          3.25845591e-04,   6.98893740e-03,   6.61029276e-03,\n",
       "          7.77892786e-03,   1.57691989e-02,   1.33014316e-02,\n",
       "          8.27689422e-06,   9.99097611e-03,   9.34352768e-03,\n",
       "          1.77467036e-02,   1.44022643e-02,   1.60866789e-02,\n",
       "          2.95604453e-03,   6.42454984e-03,   1.19200414e-02,\n",
       "          3.42579178e-03,   1.14891869e-02,   1.03886083e-02,\n",
       "          6.75543625e-03,   1.58726397e-05,   9.46825765e-03,\n",
       "          4.73774627e-04,   5.23693772e-03,   1.21074723e-02,\n",
       "          3.37174788e-07,   1.35012086e-05,   8.27428292e-03,\n",
       "          9.52938356e-03,   3.04282928e-02,   2.67442509e-02,\n",
       "          7.68206528e-06,   5.88533525e-03,   1.57717534e-03,\n",
       "          9.41377303e-03,   6.08912968e-03,   5.54075777e-03,\n",
       "          7.47961111e-06,   6.83814726e-03,   7.92968119e-03,\n",
       "          1.16799621e-02,   1.22353740e-02,   2.83494490e-02,\n",
       "          7.35081104e-03,   7.20306124e-03,   1.21936303e-05,\n",
       "          6.10578688e-03,   6.92410057e-02,   3.07001982e-02,\n",
       "          1.91884479e-03,   2.68002963e-03,   3.13917345e-02,\n",
       "          2.51129179e-02,   7.23012757e-02,   6.35852691e-02,\n",
       "          5.84504624e-03,   8.11523144e-03,   6.19917646e-03,\n",
       "          5.77476294e-03,   1.72239370e-02,   5.73913984e-03,\n",
       "          5.79132505e-03,   8.48063298e-06,   1.40106387e-02,\n",
       "          7.12903394e-03,   1.91154581e-03,   6.69000237e-02,\n",
       "          4.31981601e-03,   4.03596748e-03,   3.97569169e-02,\n",
       "          3.14520760e-02,   6.77620039e-03,   1.18310549e-02,\n",
       "          8.85103888e-06,   6.29629584e-03,   2.50550297e-03,\n",
       "          4.23271208e-02,   5.35122332e-02,   3.57006030e-02,\n",
       "          9.03000589e-03,   4.85049485e-03,   2.59542574e-02,\n",
       "          2.48460911e-02,   2.24743019e-02,   6.00446998e-03,\n",
       "          3.38596692e-03,   6.88293650e-03,   1.89181612e-05,\n",
       "          7.20419213e-03,   9.96562237e-03,   6.76763678e-03,\n",
       "          9.32941222e-06,   6.76633976e-03,   7.80285003e-03,\n",
       "          6.76355753e-03,   6.98488512e-03,   6.60312755e-03,\n",
       "          6.76606436e-03,   4.63922972e-03,   7.01460841e-03,\n",
       "          1.76326295e-03,   6.79746255e-03,   2.81702583e-03,\n",
       "          6.76324711e-03,   1.56795340e-06,   1.02479200e-02,\n",
       "          3.12608448e-03,   1.18881012e-05,   1.26032379e-02,\n",
       "          7.72564494e-07,   6.76585791e-03,   7.18637134e-03,\n",
       "          7.86398448e-03,   3.52699724e-03,   7.81316623e-03,\n",
       "          6.76211219e-03,   6.82206341e-07,   1.02675701e-02,\n",
       "          1.10617804e-02,   4.75954303e-03,   6.37987971e-03,\n",
       "          6.76307493e-03,   7.97455797e-07,   7.80296984e-03,\n",
       "          7.51229426e-03,   6.71457515e-03,   6.09429022e-03,\n",
       "          6.76596113e-03,   1.97686242e-07,   7.41144125e-03,\n",
       "          6.77164405e-03,   7.80285160e-03,   6.21637065e-03,\n",
       "          2.38418579e-07,   4.57831964e-07,   6.38382420e-03,\n",
       "          7.81257140e-03,   6.62740950e-03,   6.64198900e-03,\n",
       "          2.66560075e-07,   3.09714819e-07,   6.92747184e-03,\n",
       "          1.09418639e-02,   8.13424909e-03,   7.80892702e-03,\n",
       "          6.76611414e-03,   7.02728398e-07,   5.00144883e-04,\n",
       "          7.14372912e-03,   4.47002961e-03,   4.64483391e-03,\n",
       "          7.81273843e-03,   1.22153172e-06,   5.42207830e-04,\n",
       "          6.77457475e-03,   6.76947551e-03,   1.33811711e-04,\n",
       "          5.93058727e-07,   6.76816692e-03,   7.80761512e-03,\n",
       "          2.04742634e-03,   9.72833167e-03,   4.93224929e-03,\n",
       "          9.57614983e-06,   4.91512492e-07,   6.43856164e-03,\n",
       "          1.10485435e-02,   6.83929751e-03,   3.49702178e-03,\n",
       "          6.76899352e-03,   4.25861204e-03,   6.38460319e-03,\n",
       "          8.77130762e-03,   1.10493864e-02,   6.75617112e-03,\n",
       "          1.78714566e-06,   6.88534743e-04,   8.42674264e-03,\n",
       "          1.56163006e-02,   2.72333349e-02,   7.81399807e-03,\n",
       "          6.76865037e-03,   6.76242209e-03,   6.60052902e-03,\n",
       "          6.65307736e-03,   1.20707352e-02,   7.58111722e-03,\n",
       "          7.02728398e-07,   1.31588644e-05,   6.76590318e-03,\n",
       "          5.37637897e-04,   5.63404456e-03,   5.88826436e-03,\n",
       "          6.76592671e-03,   4.29815206e-07,   1.47395116e-02,\n",
       "          7.81792693e-03,   3.63666842e-02,   1.24065521e-02,\n",
       "          1.48191244e-03,   5.44396514e-03,   1.40993650e-05,\n",
       "          5.31350642e-03,   3.29580389e-03,   2.25462346e-03]),\n",
       " 'std_score_time': array([  4.33222546e-04,   6.76582347e-03,   5.58451297e-03,\n",
       "          5.56299867e-03,   2.33348582e-03,   6.38256055e-03,\n",
       "          4.33015938e-04,   8.66582065e-04,   8.41368340e-03,\n",
       "          8.21482418e-03,   1.82143285e-03,   6.47244926e-03,\n",
       "          8.66685303e-04,   6.02513657e-03,   6.37989485e-03,\n",
       "          6.50031824e-03,   6.38164728e-03,   6.57256944e-03,\n",
       "          0.00000000e+00,   6.94549212e-03,   5.63569148e-03,\n",
       "          7.41839500e-03,   6.36468848e-03,   6.46726982e-03,\n",
       "          3.56234379e-06,   6.51966435e-03,   3.77760418e-03,\n",
       "          3.41551537e-03,   2.43267228e-03,   6.76572023e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.40030259e-03,\n",
       "          6.77459872e-03,   6.56905303e-03,   7.47300376e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.77814902e-03,\n",
       "          5.65462785e-03,   6.38049162e-03,   5.27150158e-03,\n",
       "          6.76520404e-03,   4.96297594e-04,   0.00000000e+00,\n",
       "          6.38844316e-03,   2.00028990e-03,   7.81273842e-03,\n",
       "          6.76551375e-03,   6.25047725e-03,   2.69681447e-03,\n",
       "          8.66651584e-04,   1.25096044e-03,   3.29600972e-03,\n",
       "          8.66169111e-04,   9.95604647e-04,   6.77346310e-03,\n",
       "          3.03396637e-03,   1.13922847e-02,   8.77653757e-03,\n",
       "          1.41495427e-03,   2.87061174e-03,   6.42657554e-03,\n",
       "          3.90166141e-03,   9.01614796e-03,   4.02451518e-03,\n",
       "          6.39306750e-03,   8.29707137e-04,   1.99925463e-03,\n",
       "          6.38770954e-03,   3.08054939e-03,   7.82275201e-03,\n",
       "          8.29581332e-04,   6.76602994e-03,   6.38809052e-03,\n",
       "          7.81321530e-03,   6.48089774e-03,   1.29439595e-02,\n",
       "          1.00261314e-03,   1.79043815e-03,   4.16150614e-03,\n",
       "          4.06949509e-03,   7.81739035e-03,   1.37401312e-05,\n",
       "          6.86420954e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.66273786e-03,   9.36355298e-03,   1.19788115e-02,\n",
       "          4.97999982e-04,   4.34846110e-04,   2.77300378e-03,\n",
       "          2.12040291e-03,   8.62157186e-03,   6.70692698e-03,\n",
       "          8.34231114e-04,   6.48987312e-03,   0.00000000e+00,\n",
       "          2.87198523e-03,   6.38192026e-03,   6.76623642e-03,\n",
       "          0.00000000e+00,   6.77418577e-03,   6.76572023e-03,\n",
       "          7.81250001e-03,   7.81267883e-03,   7.81303645e-03,\n",
       "          6.76530728e-03,   8.74944365e-04,   2.59984943e-03,\n",
       "          2.59995267e-03,   6.38946401e-03,   5.41853549e-03,\n",
       "          6.76572023e-03,   0.00000000e+00,   6.37959136e-03,\n",
       "          6.76602994e-03,   7.09370401e-06,   6.38167202e-03,\n",
       "          6.76623642e-03,   0.00000000e+00,   6.65902262e-03,\n",
       "          2.60005591e-03,   6.76589230e-03,   6.76578908e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.76613318e-03,\n",
       "          7.81762921e-03,   6.70611640e-03,   6.76568585e-03,\n",
       "          6.76602994e-03,   0.00000000e+00,   7.81267882e-03,\n",
       "          6.76623642e-03,   8.31223048e-06,   7.81339411e-03,\n",
       "          6.76561699e-03,   0.00000000e+00,   5.86568902e-03,\n",
       "          7.80797282e-03,   7.33770119e-03,   7.81285764e-03,\n",
       "          6.76572023e-03,   0.00000000e+00,   6.76582347e-03,\n",
       "          6.76654613e-03,   7.33562853e-03,   6.38154517e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.63846217e-03,   7.81267881e-03,   7.81309605e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.82215600e-03,\n",
       "          8.57053172e-03,   6.76620206e-03,   7.81285763e-03,\n",
       "          6.76602994e-03,   0.00000000e+00,   6.76592671e-03,\n",
       "          6.76572023e-03,   6.75746117e-03,   7.81279803e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.76602996e-03,\n",
       "          6.76613318e-03,   6.38402119e-03,   7.80743674e-03,\n",
       "          6.76530728e-03,   0.00000000e+00,   6.76613318e-03,\n",
       "          6.76837633e-03,   7.81238080e-03,   7.81768873e-03,\n",
       "          6.76582347e-03,   8.66685303e-04,   6.38790665e-03,\n",
       "          7.81273843e-03,   7.32755600e-03,   6.76307563e-03,\n",
       "          0.00000000e+00,   8.66788541e-04,   6.76592671e-03,\n",
       "          6.76695909e-03,   0.00000000e+00,   7.81697277e-03,\n",
       "          0.00000000e+00,   0.00000000e+00,   7.82251360e-03,\n",
       "          6.76620202e-03,   6.76623644e-03,   7.81756938e-03,\n",
       "          6.76644290e-03,   6.77439224e-03,   7.81744935e-03,\n",
       "          6.76572023e-03,   0.00000000e+00,   6.50440797e-03,\n",
       "          6.76613318e-03,   6.77428901e-03,   5.78990590e-03,\n",
       "          7.81273842e-03,   2.87244051e-03,   1.70404363e-04,\n",
       "          8.34293576e-04,   6.76592671e-03,   7.81261921e-03,\n",
       "          0.00000000e+00,   6.76585788e-03,   3.08032036e-03]),\n",
       " 'std_test_score': array([ 0.0113233 ,  0.01744233,  0.00853128,  0.01622073,  0.011899  ,\n",
       "         0.00741271,  0.02589056,  0.01016356,  0.00741932,  0.01023529,\n",
       "         0.00844076,  0.01649189,  0.01045444,  0.00396922,  0.00559493,\n",
       "         0.00669554,  0.00551325,  0.00184273,  0.00570161,  0.00678184,\n",
       "         0.00411689,  0.0032038 ,  0.0032038 ,  0.00551396,  0.00602166,\n",
       "         0.01253881,  0.01221004,  0.01196112,  0.00650765,  0.00636903,\n",
       "         0.00529799,  0.01517104,  0.00598358,  0.00475522,  0.00628511,\n",
       "         0.00693638,  0.00742594,  0.0165607 ,  0.00742594,  0.00819446,\n",
       "         0.00571183,  0.0021237 ,  0.01517055,  0.01012703,  0.00872636,\n",
       "         0.00551603,  0.01269639,  0.00944666,  0.00608408,  0.00879086,\n",
       "         0.00536368,  0.00879086,  0.00767896,  0.00608408,  0.00569929,\n",
       "         0.00569929,  0.00569929,  0.00569929,  0.00569929,  0.00569929,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.01145149,  0.02917134,  0.01765967,\n",
       "         0.0240831 ,  0.02036309,  0.01866329,  0.02574125,  0.02247651,\n",
       "         0.02228267,  0.01096443,  0.00943866,  0.00952647,  0.00460841,\n",
       "         0.02632843,  0.00376022,  0.00833957,  0.00599396,  0.00201828,\n",
       "         0.00854366,  0.07083051,  0.00496785,  0.00282393,  0.01518555,\n",
       "         0.00405886,  0.0132425 ,  0.01285683,  0.00680561,  0.01526976,\n",
       "         0.01527977,  0.00962032,  0.00918927,  0.01738242,  0.01195348,\n",
       "         0.01574662,  0.01346898,  0.00908915,  0.01156708,  0.0098458 ,\n",
       "         0.01604032,  0.00535664,  0.00251948,  0.00885839,  0.00320259,\n",
       "         0.00410125,  0.01360948,  0.01466317,  0.01107647,  0.01178855,\n",
       "         0.01806896,  0.0144782 ,  0.01043222,  0.00851296,  0.01390007,\n",
       "         0.00695186,  0.01549124,  0.01489608,  0.01430857,  0.01680143,\n",
       "         0.01489608,  0.01447475,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00738634,\n",
       "         0.01189896,  0.00921174,  0.02281483,  0.01845341,  0.01893372,\n",
       "         0.01839082,  0.01040841,  0.01433405,  0.01391648,  0.01677114,\n",
       "         0.01464023,  0.00677573,  0.01383677,  0.00660722,  0.00740661,\n",
       "         0.00529799,  0.00201828,  0.01592021,  0.01676153,  0.0059975 ,\n",
       "         0.00529799,  0.00491836,  0.00253151,  0.02940089,  0.02544874,\n",
       "         0.01235268,  0.01525399,  0.00751071,  0.00861978,  0.0110107 ,\n",
       "         0.00827704,  0.01692632,  0.00964139,  0.0090858 ,  0.01740182,\n",
       "         0.00551255,  0.00353461,  0.0068002 ,  0.00551255,  0.00237642,\n",
       "         0.00353461,  0.01932829,  0.00551255,  0.00202568,  0.00518518,\n",
       "         0.01107647,  0.00652084,  0.0122854 ,  0.01735301,  0.01168855,\n",
       "         0.0178374 ,  0.01259866,  0.01446522,  0.01622073,  0.02200565,\n",
       "         0.01489608,  0.01447475,  0.01622073,  0.01622073,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839,  0.00885839,  0.00885839,  0.00885839,  0.00885839,\n",
       "         0.00885839]),\n",
       " 'std_train_score': array([ 0.00960992,  0.01253606,  0.0133314 ,  0.00061762,  0.00784514,\n",
       "         0.00834854,  0.01097557,  0.0086561 ,  0.019921  ,  0.01495639,\n",
       "         0.00776512,  0.00802989,  0.00580959,  0.01082832,  0.00238288,\n",
       "         0.00424802,  0.00890685,  0.00190525,  0.00932834,  0.00725894,\n",
       "         0.01201311,  0.00658059,  0.00468185,  0.00156383,  0.00587656,\n",
       "         0.01906158,  0.01252533,  0.01201543,  0.00706104,  0.00646788,\n",
       "         0.00654453,  0.01014822,  0.00572392,  0.00695966,  0.00143113,\n",
       "         0.01291955,  0.00495251,  0.00798314,  0.00636968,  0.00688939,\n",
       "         0.00934163,  0.00911972,  0.01870041,  0.0067614 ,  0.00743017,\n",
       "         0.00051063,  0.00117192,  0.00743017,  0.00611847,  0.00501369,\n",
       "         0.00535703,  0.00565347,  0.00500257,  0.00436975,  0.00190349,\n",
       "         0.00190349,  0.00190349,  0.00190349,  0.00190349,  0.00190349,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00807445,  0.00349756,  0.00534558,\n",
       "         0.00854647,  0.00478452,  0.0040793 ,  0.00464365,  0.00907973,\n",
       "         0.00700793,  0.01268001,  0.0143273 ,  0.00985119,  0.00580315,\n",
       "         0.01589242,  0.00478279,  0.00808444,  0.0017688 ,  0.00424726,\n",
       "         0.01250574,  0.04848041,  0.00550421,  0.00801606,  0.00514976,\n",
       "         0.00600508,  0.0096793 ,  0.00612537,  0.00862573,  0.01111707,\n",
       "         0.00670399,  0.00842282,  0.01052916,  0.01081273,  0.00381855,\n",
       "         0.01180611,  0.00919105,  0.0085566 ,  0.02001337,  0.00985825,\n",
       "         0.00490939,  0.00738376,  0.00578808,  0.00428007,  0.00818998,\n",
       "         0.0078693 ,  0.00431634,  0.00472019,  0.00884328,  0.00763452,\n",
       "         0.00364609,  0.00382047,  0.01107981,  0.0112099 ,  0.00810517,\n",
       "         0.00842986,  0.00604601,  0.0068879 ,  0.0067791 ,  0.00541968,\n",
       "         0.00666453,  0.00820114,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.01406029,\n",
       "         0.01090287,  0.00945956,  0.00980166,  0.00737175,  0.00585009,\n",
       "         0.01740186,  0.00547357,  0.00824956,  0.01263538,  0.01427994,\n",
       "         0.0073074 ,  0.00632891,  0.00461637,  0.00413978,  0.00748217,\n",
       "         0.00686981,  0.00441645,  0.00385776,  0.01595792,  0.00476108,\n",
       "         0.00487705,  0.00361466,  0.00111704,  0.01047151,  0.00944567,\n",
       "         0.00765167,  0.00969328,  0.01211245,  0.01173977,  0.00849085,\n",
       "         0.00964962,  0.01230826,  0.00345022,  0.00986836,  0.00526187,\n",
       "         0.00597775,  0.00486388,  0.0038961 ,  0.00796043,  0.00483987,\n",
       "         0.00550661,  0.00992261,  0.00659679,  0.00723949,  0.00760389,\n",
       "         0.00475644,  0.00716915,  0.00947453,  0.00913944,  0.00310936,\n",
       "         0.00583819,  0.00402198,  0.00658647,  0.00567473,  0.00686164,\n",
       "         0.00688793,  0.00692061,  0.0073657 ,  0.00789358,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763,  0.00294763,  0.00294763,  0.00294763,  0.00294763,\n",
       "         0.00294763])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_RFC.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_estimator = RandomForestClassifier(max_depth=6,\n",
    "                                  max_features= 3,\n",
    "                                  min_samples_leaf= 10,\n",
    "                                  n_estimators= 50,\n",
    "                                  warm_start= 0)\n",
    "rfc_estimator_fitted = rf_estimator.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Random Forest Classifier @ kaggle - 0.78947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №2 для GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'n_estimators':[3,10,50,100],\n",
    "       'learning_rate':[0.03,0.3,3],\n",
    "       'max_depth':[2,6,10],\n",
    "       'min_samples_leaf':[10,30,70,100]\n",
    "       }\n",
    "\n",
    "gridSearchGradientBoosting = GridSearchCV(GradientBoostingClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Slava-N\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:256: RuntimeWarning: overflow encountered in multiply\n",
      "  * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
      "C:\\Users\\Slava-N\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:490: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n",
      "C:\\Users\\Slava-N\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:256: RuntimeWarning: overflow encountered in multiply\n",
      "  * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n",
      "C:\\Users\\Slava-N\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:490: RuntimeWarning: invalid value encountered in multiply\n",
      "  np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n"
     ]
    }
   ],
   "source": [
    "param_finder_GBC = gridSearchGradientBoosting.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.03,\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_GBC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_estimator = GradientBoostingClassifier(n_estimators=10, max_depth=6, min_samples_leaf=30, learning_rate=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_estimator_fitted = gb_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single GradientBoostingClassifier @ kaggle - 0.77512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №3 для Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'max_depth':list(range(2,10,1)),\n",
    "       'min_samples_leaf':[10,30,70,100]}\n",
    "\n",
    "gridSearchDecisionTree = GridSearchCV(DecisionTreeClassifier(), grid, cv = kfold, scoring = 'accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_finder_DT = gridSearchDecisionTree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_estimator = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_estimator_fitted = dt_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single Decision Tree @ kaggle - 0.78469"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №4  для SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9]}\n",
    "\n",
    "gridSearchSupportVector = GridSearchCV(LinearSVC(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_finder_SVC = gridSearchSupportVector.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80717489,  0.75784753,  0.84304933,  0.77927928])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(LinearSVC(C=0.03),\n",
    "                         X_train, y_train, groups=None,\n",
    "                        scoring = make_scorer(accuracy_score),\n",
    "                        cv=kfold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_estimator = LinearSVC(C=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_estimator_fitted = svc_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single LinearSVC @ kaggle - 0.75\n",
    "Самый плохой показатель, в стекинг моделей в любом случае не включаем - отсутствует метод оценки вероятности для предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров модели №5  для LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9]}\n",
    "\n",
    "gridSearchLogisticRegression = GridSearchCV(LogisticRegression(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_finder_LR = gridSearchLogisticRegression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.9}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_finder_LR.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_estimator = LogisticRegression(C=6)\n",
    "LR_estimator_fitted = LR_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single LogisticRegression @ kaggle - 0.76077\n",
    "Достаточно низкий показатель, в любом случае идет в стеккинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формирование матрицы предсказаний четырех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем предсказания вероятностей ансамблей на кросс-валидации для обучающей выборки\n",
    "rf_train_pred = cross_val_predict_proba(rf_estimator, X_train, y_train)\n",
    "gb_train_pred = cross_val_predict_proba(gb_estimator, X_train, y_train)\n",
    "dt_train_pred = cross_val_predict_proba(dt_estimator, X_train, y_train)\n",
    "lr_train_pred = cross_val_predict_proba(LR_estimator, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack = np.stack([rf_train_pred[:,1], gb_train_pred[:,1], dt_train_pred[:,1],lr_train_pred[:,1]], axis=1)\n",
    "\n",
    "# получаем предсказания ансамблей для тестовой выборки\n",
    "rf_test_pred = rfc_estimator_fitted.predict_proba(X_test)\n",
    "gb_test_pred = gb_estimator_fitted.predict_proba(X_test)\n",
    "dt_test_pred = dt_estimator_fitted.predict_proba(X_test)\n",
    "lr_test_pred = LR_estimator_fitted.predict_proba(X_test)\n",
    "\n",
    "\n",
    "X_test_stack = np.stack([rf_test_pred[:,1], gb_test_pred[:,1],dt_test_pred[:,1],lr_test_pred[:,1]], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединяем предсказания ансамблей с помощью логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C':[0.03, 0.3, 0.9, 3, 6, 9,15,50]}\n",
    "gridSearchEnsemble = GridSearchCV(LogisticRegression(), grid, cv = kfold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=4, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.03, 0.3, 0.9, 3, 6, 9, 15, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchEnsemble.fit(X_train_stack, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridSearchEnsemble.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При таком значении модель переобучается. Взято значение 0.5 - дает наилучший результат\n",
    "\n",
    "50 0.7799\n",
    "0.5 0.78794\n",
    "0.03 0.78469"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: подобрать гиперпараметры LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=0.5).fit(X_train_stack, y_train)\n",
    "predicted = logreg.predict(X_test_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формируем фалй для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission_ensemble_3_models_regularization_9.txt', 'w') as out:\n",
    "    out.write('PassengerId,Survived\\n')\n",
    "    for passenger, y in zip(test['PassengerId'], predicted):\n",
    "        out.write('%s,%s\\n' % (passenger, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
